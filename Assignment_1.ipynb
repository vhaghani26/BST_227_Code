{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vhaghani26/BST_227_Code/blob/main/Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEB6Jbmxr9P7"
      },
      "source": [
        "# **The EM Algorithm for a more complex sequence model**\n",
        "## By: Mariele Lensink and Viktoria Haghani"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zDlf51Mr6wp"
      },
      "source": [
        "First, we need to import the modules we plan to use to run the code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yrbLTPNtux7"
      },
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from tqdm import tqdm\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4CTnzFwsnzw"
      },
      "source": [
        "# **EM Algorithm Code and Impelementation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdktorRL4uEj"
      },
      "source": [
        "Write a function to download and one-hot encoded the sequence data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ka8lwgcXZ5XF"
      },
      "source": [
        "# Function written by Chenxi Liu (slight modifications made)\n",
        "\n",
        "def get_sequence(url, categories=['A', 'C', 'G', 'T']):\n",
        "  # Send a GET request to a specified URL, categories=['A', 'C', 'G', 'T']):\n",
        "  r = requests.get(url)\n",
        "  # Convert sequence data to data frame\n",
        "  df = pd.read_csv(io.StringIO(r.text), sep=\" \", header=None)\n",
        "  # Turn the first sequence into a 2D array where each index is an independent array with a single base pair\n",
        "  s1 = np.array(list(str(df.to_numpy()[0, :][0])), dtype=object).reshape(-1, 1)\n",
        "\n",
        "  # Determine how many sequences there are in the text file\n",
        "  num_seqs = len(df)\n",
        "  # Assume all input sequences are equal length\n",
        "  # Determine how long each sequence is\n",
        "  seq_len = len(list(df.iloc[0, :].values)[0])\n",
        "  # Start to make a one-hot encoded 3D matrix for the seqeunces\n",
        "  # Not one-hot encoded yet, just zeroes \n",
        "  data = np.zeros((num_seqs, seq_len, len(categories)))\n",
        "  # Make a matrix repersenting each category ['A', 'C', 'G', 'T']\n",
        "  bp_counts = np.zeros((1, len(categories)))\n",
        "\n",
        "  # Encode categorical feautures in a one-hot numeric array\n",
        "  # Assign categories to be used\n",
        "  ohe = OneHotEncoder(sparse=False, categories=[np.array(categories, dtype=object)])\n",
        "  # Apply OneHotEncoder to example sequence\n",
        "  ohe.fit(s1)\n",
        "  \n",
        "  # Apply OneHotEncoder to all sequences\n",
        "  for ii in tqdm(range(num_seqs)):\n",
        "    s = list(str(df.to_numpy()[ii, :][0]))\n",
        "    s_a = np.array(s).reshape(-1, 1)\n",
        "    data[ii, :, :] = ohe.transform(s_a)\n",
        "  \n",
        "  # Count the number of each base in the sequence data\n",
        "  for ii in range(len(categories)):\n",
        "    bp_counts[0,ii] = np.sum(data[:,:,ii])\n",
        "  \n",
        "  # Return the one-hot encoded matrix (data),\n",
        "  # the counts for each base pair (bp_counts),\n",
        "  # the number of sequences (N),\n",
        "  # and the length of each sequence (L)\n",
        "  return data, bp_counts                                                  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "od2WQCQrDDyv"
      },
      "source": [
        "Write a modified version of the above function that returns a randomly split training and test data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJGr38gKDNuE"
      },
      "source": [
        "# Function written by Chenxi Liu and Gerald Quon\n",
        "\n",
        "def get_sequence_traintest(url, categories=['A', 'C', 'G', 'T'], FRACTION_TRAINING=0.8):\n",
        "  # Send a GET request to a specified URL, categories=['A', 'C', 'G', 'T']):\n",
        "  r = requests.get(url)\n",
        "  # Convert sequence data to data frame\n",
        "  df = pd.read_csv(io.StringIO(r.text), sep=\" \", header=None)\n",
        "  # Turn the first sequence into a 2D array where each index is an independent array with a single base pair\n",
        "  s1 = np.array(list(str(df.to_numpy()[0, :][0])), dtype=object).reshape(-1, 1)\n",
        "\n",
        "  # Determine how many sequences there are in the text file\n",
        "  m = len(df)\n",
        "  # Assume all input sequences are equal length\n",
        "  # Determine how long each sequence is\n",
        "  sequence_len = len(list(df.iloc[0, :].values)[0])\n",
        "  # Start to make a one-hot encoded 3D matrix for the seqeunces\n",
        "  # Not one-hot encoded yet, just zeroes \n",
        "  data = np.zeros((m, sequence_len, len(categories)))\n",
        "  # Make a matrix repersenting each category ['A', 'C', 'G', 'T'] for the training set\n",
        "  bp_counts_train = np.zeros((1, len(categories)))\n",
        "  # Make a matrix repersenting each category ['A', 'C', 'G', 'T'] for the test set\n",
        "  bp_counts_test = np.zeros((1, len(categories)))\n",
        "\n",
        "  # Encode categorical feautures in a one-hot numeric array\n",
        "  # Assign categories to be used\n",
        "  ohe = OneHotEncoder(sparse=False, categories=[np.array(categories, dtype=object)])\n",
        "  # Apply OneHotEncoder to example sequence\n",
        "  ohe.fit(s1)\n",
        "\n",
        "  # Apply OneHotEncoder to all sequences\n",
        "  for ii in tqdm(range(m)):\n",
        "    s = list(str(df.to_numpy()[ii, :][0]))\n",
        "    s_a = np.array(s).reshape(-1, 1)\n",
        "    data[ii, :, :] = ohe.transform(s_a)\n",
        "\n",
        "  # Randomly permute rows of matrix\n",
        "  np.random.shuffle(data)\n",
        "\n",
        "  # Split data into training and text data\n",
        "  train_indices = np.arange(start=0,stop=round(FRACTION_TRAINING*data.shape[0]))\n",
        "  test_indices = np.arange(start=round(FRACTION_TRAINING*data.shape[0]), stop=data.shape[0])\n",
        "  \n",
        "  # Count the number of each base in the test and train sets\n",
        "  for ii in range(len(categories)):\n",
        "    bp_counts_train[0,ii] = np.sum(data[train_indices,:,ii])\n",
        "    bp_counts_test[0,ii] = np.sum(data[test_indices,:,ii])\n",
        "  \n",
        "  # Return the base pair counts for the test and train sets\n",
        "  return bp_counts_train, bp_counts_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9liLSAMwHEe"
      },
      "source": [
        "Set data file URL locations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "143x5QHNwKZg"
      },
      "source": [
        "# URL for at_gc_sequences.txt - this is a single sequence: ATTTAATATAAAATTTGGCCGCCATAAAAAAA\n",
        "at_gc_sequences_txt = 'https://ucdavis.box.com/shared/static/s8g6zx9vwxbbfdxdj2uqzhlvslc1jhsy.txt'\n",
        "# URL for sequence.padded.txt - the real binding site data\n",
        "sequence_padded_txt = 'https://ucdavis.box.com/shared/static/0cacx2xvn4ugxo9h21ci2ngesryigf43.txt'\n",
        "# URL for sequence.motiflocation.padded.txt - the location of the binding sites from sequence.padded.txt\n",
        "sequence_motiflocation_padded_txt = 'https://ucdavis.box.com/shared/static/gd0r12mdkhix86bo9ffbn3dy0fy0prmn.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5H6PrulrH9ap"
      },
      "source": [
        "Load in the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxoFtgmPH_Ev",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d03f16b7-7968-4463-9e5c-6818f1787781"
      },
      "source": [
        "# Implement get_sequence()\n",
        "# The variable my_ohe_sequence_padded corresponds to the one-hot encoded matrices that represent the sequence data\n",
        "# The variable my_sequence_padded_bp_counts is the base pair counts for the input sequence data\n",
        "# The variable my_sequence_padded_num_seqs returns the number of sequences in the sequence file\n",
        "# sequence_padded_txt is the variable name containing the URL defined at the beginning\n",
        "my_ohe_sequence_padded, my_sequence_padded_bp_counts = get_sequence(sequence_padded_txt, categories=['A', 'C', 'G', 'T'])\n",
        "\n",
        "# Following similar notation above, we can implement get_sequence() for the at_gc_sequences_text data\n",
        "my_ohe_at_gc_sequences, my_at_gc_bp_counts = get_sequence(at_gc_sequences_txt, categories=['A', 'C', 'G', 'T'])\n",
        "\n",
        "# Now randomly split the sequence_padded_txt into a training vs test set\n",
        "sequence_padded_train_bp_counts, sequence_padded_test_bp_counts = get_sequence_traintest(sequence_padded_txt, categories=['A', 'C', 'G', 'T'])\n",
        "\n",
        "# Get the locations of the motifs for the sequence.padded.txt file\n",
        "sequence_padded_motifs = pd.read_csv(io.StringIO(requests.get(sequence_motiflocation_padded_txt).text), sep=\",\", header=None).to_numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 357/357 [00:00<00:00, 2397.47it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 740.00it/s]\n",
            "100%|██████████| 357/357 [00:00<00:00, 1928.73it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K12xuvJwvbMi"
      },
      "source": [
        "Assign EM run variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OBpGUmTvdri"
      },
      "source": [
        "# Length of the motif\n",
        "motif_length = 18\n",
        "\n",
        "# Sequence data used\n",
        "seq_data = my_ohe_sequence_padded\n",
        "\n",
        "# Set the number of sequences\n",
        "num_seqs = len(seq_data)\n",
        "\n",
        "# Set the length of the sequences\n",
        "seq_len = len(seq_data[0])\n",
        "\n",
        "# Set the number of EM iterations\n",
        "num_iterations = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbAXV5YlM9p0"
      },
      "source": [
        "Write functions that will initialize our parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0uB6d0_M_b-"
      },
      "source": [
        "# Make a function to randomly generate L - P + 1 lambdas that sum to 1\n",
        "def initialize_lambda(sequence_length, motif_length):\n",
        "  # Make an empty list to represent our parameter lambda_j\n",
        "  lambda_j = []\n",
        "  # Given our sequence length and motif length, determine how many lambdas we need\n",
        "  lambdas = sequence_length - motif_length + 1\n",
        "  # Fill up our empty matrix with the right number of lambdas using random probabilities\n",
        "  for i in range(lambdas):\n",
        "    lambda_j.append(np.random.random_sample())\n",
        "  # Normalize probabilities by dividing each one by the sum\n",
        "  # Need to set sum_lambdas on the outside of the for loop so it isn't recalculated every time\n",
        "  sum_lambdas = sum(lambda_j)\n",
        "  for i, lmbda in zip(range(lambdas), lambda_j):\n",
        "    lambda_j[i] = (lmbda/sum_lambdas)\n",
        "  # Return our lambda_j parameter\n",
        "  return lambda_j"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-wAaxEgsUYD"
      },
      "source": [
        "# Make a function to randomly generate psi\n",
        "# Psi is a 2D matrix: 4 x P (P = motif-length) \n",
        "# Each set of 4 corresponds to ['A', 'C', 'G', 'T']\n",
        "def initialize_psi(motif_length):\n",
        "  # Make a 4 x P matrix of zeroes\n",
        "  psi = np.zeros((motif_length, 4), dtype = float)\n",
        "  # For each sub-matrix of 4, generate probabilities that sum to 1\n",
        "  for ind_i, i in zip(range(motif_length), psi):\n",
        "    psi[ind_i] = (np.random.dirichlet(np.ones(4),size=1))\n",
        "  # Return our psi parameter\n",
        "  return psi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vrifajwsUoK"
      },
      "source": [
        "# Store all initialized parameters in a dictionary called 'params' (params = theta)\n",
        "def initialize_random_params(sequence_length, motif_length):\n",
        "    params = {'lambda_j': initialize_lambda(sequence_length, motif_length),\n",
        "              'psi0': initialize_psi(motif_length),\n",
        "              'psi1': initialize_psi(motif_length)\n",
        "              }\n",
        "    return params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWTR8KVf1vxP"
      },
      "source": [
        "Initiate parameters to use for troubleshooting the E-step and M-step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bs9Ry8Kx10K8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "846c3f64-f8cd-49eb-8247-252a01c41885"
      },
      "source": [
        "params = initialize_random_params(seq_len, motif_length)\n",
        "print(params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'lambda_j': [0.042946970569195206, 0.057602681855774995, 0.025084282743291244, 0.04551880823443254, 0.060859561384307044, 0.06503470458266886, 0.07645426987965706, 0.021458243871172067, 0.07212212894891261, 0.02316680606119309, 0.006293929929217782, 0.030926337119321124, 0.0500646561013798, 0.07559219958166634, 0.07604606022766656, 0.04905130489853712, 0.0784774736699738, 0.043336746904850336, 0.0045701992852181855, 0.039010963788863776, 0.0563816703627004], 'psi0': array([[0.13245539, 0.78740673, 0.07114879, 0.0089891 ],\n",
            "       [0.10036227, 0.12137644, 0.06782981, 0.71043149],\n",
            "       [0.24533983, 0.20607278, 0.42474499, 0.1238424 ],\n",
            "       [0.12051303, 0.61187012, 0.08970087, 0.17791598],\n",
            "       [0.41861101, 0.14063389, 0.41547301, 0.02528209],\n",
            "       [0.32285799, 0.12547061, 0.34979191, 0.20187949],\n",
            "       [0.26872321, 0.54098779, 0.09696363, 0.09332538],\n",
            "       [0.23724457, 0.15336649, 0.43550055, 0.1738884 ],\n",
            "       [0.14726501, 0.0606734 , 0.08843086, 0.70363073],\n",
            "       [0.34781463, 0.26495256, 0.34340354, 0.04382927],\n",
            "       [0.40830691, 0.2772554 , 0.29964354, 0.01479415],\n",
            "       [0.17161305, 0.11576075, 0.62564861, 0.08697758],\n",
            "       [0.37072353, 0.10962551, 0.40703084, 0.11262012],\n",
            "       [0.04020048, 0.01172714, 0.10404018, 0.84403221],\n",
            "       [0.11895807, 0.24125346, 0.52893327, 0.1108552 ],\n",
            "       [0.0892909 , 0.086204  , 0.17617179, 0.64833332],\n",
            "       [0.31886327, 0.11881808, 0.35268908, 0.20962957],\n",
            "       [0.53033546, 0.30173851, 0.14224845, 0.02567758]]), 'psi1': array([[0.08201698, 0.36051397, 0.34206489, 0.21540416],\n",
            "       [0.00497213, 0.0274008 , 0.91527938, 0.0523477 ],\n",
            "       [0.32842507, 0.16178882, 0.48693509, 0.02285102],\n",
            "       [0.14747112, 0.26258533, 0.48967299, 0.10027056],\n",
            "       [0.03535719, 0.03162404, 0.84896787, 0.0840509 ],\n",
            "       [0.52557535, 0.40989014, 0.03970491, 0.02482959],\n",
            "       [0.33746941, 0.10993287, 0.06383176, 0.48876596],\n",
            "       [0.22073576, 0.26739969, 0.45405823, 0.05780633],\n",
            "       [0.22701804, 0.13123875, 0.52656947, 0.11517374],\n",
            "       [0.48383245, 0.04370295, 0.34303563, 0.12942897],\n",
            "       [0.21979105, 0.05960114, 0.57689727, 0.14371053],\n",
            "       [0.16957595, 0.39704886, 0.3617193 , 0.07165589],\n",
            "       [0.19020122, 0.0849738 , 0.42861626, 0.29620871],\n",
            "       [0.30928678, 0.27978603, 0.10592962, 0.30499756],\n",
            "       [0.40676153, 0.05949756, 0.03780428, 0.49593664],\n",
            "       [0.01881191, 0.35206435, 0.48774732, 0.14137641],\n",
            "       [0.41174381, 0.36151991, 0.15397503, 0.07276126],\n",
            "       [0.72650972, 0.00317486, 0.14399296, 0.12632246]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC-Qv1XpvDeI"
      },
      "source": [
        "Write a function to calculate the posterior for the **E-step**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQxY3F0qvG_O"
      },
      "source": [
        "def E_step(params,ohe_matrix,sequence_length,motif_length):\n",
        "  posts = np.zeros((len(ohe_matrix),(sequence_length - motif_length + 1)))\n",
        " #loop through every seqence in file \n",
        "  for i in range(len(ohe_matrix)):\n",
        "    #loop through \n",
        "    for j in range(sequence_length - motif_length + 1):\n",
        "     #initialize C_ij \n",
        "      C_ij = np.log(params['lambda_j'][j])\n",
        "      #compute P(X_ij|Cij = 1)\n",
        "      for p in range(motif_length):\n",
        "        for k in range(4):\n",
        "          if ohe_matrix[i][j+p][k] != 0:\n",
        "            C_ij = C_ij + np.log(ohe_matrix[i][j+p][k]*params['psi1'][p][k])\n",
        "            posts[i][j] = C_ij\n",
        "      for jprime in range(sequence_length - motif_length + 1):\n",
        "        if jprime == j:\n",
        "          continue \n",
        "        for p in range(motif_length):\n",
        "          for k in range(4):\n",
        "            if ohe_matrix[i][j+p][k] != 0:\n",
        "              C_ij = C_ij + np.log(ohe_matrix[i][j+p][k]*params['psi0'][p][k])\n",
        "              posts[i][j] = C_ij\n",
        "  posts1 = np.zeros((len(posts),len(posts[0])))\n",
        "  for i in range(len(posts)):\n",
        "    rowmin = posts[i].min()\n",
        "    for j in range(len(posts[0])):\n",
        "      posts1[i][j] = math.exp(posts[i][j] - rowmin)\n",
        "      #posts1[i][j] = exp(posts1[i][j])\n",
        "    rowsum = posts1[i].sum()\n",
        "    for j in range(len(posts1[i])):\n",
        "      posts1[i][j] = posts1[i][j]/rowsum\n",
        "  # Return posterior matrix\n",
        "  return posts1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S05xOBVOvHvh"
      },
      "source": [
        "Write a function to do the calculations for the **M-step**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8xF_OTs58bA"
      },
      "source": [
        "We will start with making a practice posterior of random probabilities. This allows us to troubleshoot the M-step independent of the E-step. It does not get used in the EM algorithm implementation, but it's here for debugging purposes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m60-pmemrATK"
      },
      "source": [
        "# Make practice posterior to troubleshoot M-step\n",
        "# Run this after loading data in (data loading is in Run EM section)\n",
        "\n",
        "# Sequence data used\n",
        "seq_data = my_ohe_sequence_padded\n",
        "# Set the number of sequences\n",
        "num_seqs = len(seq_data)\n",
        "# Set the length of the sequences\n",
        "seq_len = len(seq_data[0])\n",
        "\n",
        "\n",
        "practice_posterior = []\n",
        "for i in range(num_seqs):\n",
        "  new_row = initialize_lambda(seq_len, motif_length)\n",
        "  practice_posterior.append(new_row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGa58p1LvRHp"
      },
      "source": [
        "def M_step(onehot_matrix, posterior, motif_length): \n",
        "  # Make dictionary to store new parameters\n",
        "  new_params = {}\n",
        "\n",
        "  # Calculate new lambda_j\n",
        "  # Add every column of the posterior\n",
        "  column_sums = np.array(posterior).sum(axis = 0)\n",
        "  # Divide by the total number of sequences\n",
        "  new_lambda_j = (column_sums/(len(posterior))).tolist()\n",
        "  # Confirm that the sum of our new_lambda_j is 1\n",
        "  print(f'The sum of our new lambda_j is: {sum(new_lambda_j)}')\n",
        "  # Add new_lambda_j to new_params\n",
        "  new_params[\"lambda_j\"] = new_lambda_j\n",
        "\n",
        "  # Calculate new psi1\n",
        "  # Determine how many j positions we have in our input matrix\n",
        "  num_js = len(onehot_matrix[0]) - motif_length + 1\n",
        "  # Determine matrix dimensions and save our window sequences\n",
        "  X_ijmks = []\n",
        "  for i, ind_i in zip(onehot_matrix, range(len(onehot_matrix))):\n",
        "    # Iterate through the indeces for our lambda parameter\n",
        "    for ind_j in range(num_js):\n",
        "        # i[ind_j:ind_j+motif_length] is the base pair identities of the One-Hot encoded matrix within the window starting at j\n",
        "        X_ijmk = (i[ind_j:ind_j+motif_length]).tolist()\n",
        "        # Save each X_ijmk to the X_ijmks list for ease of access\n",
        "        X_ijmks.append(X_ijmk)\n",
        "  # Manipulate the posterior so it maches the X_ijmks list\n",
        "  manipulated_posterior = []\n",
        "  for i in posterior:\n",
        "    for j in i:\n",
        "      manipulated_posterior.append(j)\n",
        "  # Make an empty list numerators, that will contain all the X_ijmks multiplied by C_ij    \n",
        "  numerators = []\n",
        "  for ind_post, X_ijmk in zip(range(len(manipulated_posterior)), X_ijmks):\n",
        "    # Turn X_ijmk into an array\n",
        "    X_ijmk_array = np.array(X_ijmk)\n",
        "    # Multiply X_ijmk by the posterior (C_ij)\n",
        "    numerator = X_ijmk_array * manipulated_posterior[ind_post]\n",
        "    # Add the multiplied window sequences to the list \"numerators\"\n",
        "    numerators.append(numerator)\n",
        "  numerator_before_normalization = np.array(numerators).sum(axis = 0)\n",
        "  new_psi1 = np.divide(numerator_before_normalization, len(onehot_matrix))\n",
        "  # Verify that new_psi1 rows sum to 1\n",
        "  print('The sums of each row in our new psi1 are:')\n",
        "  for i in range(len(new_psi1)):\n",
        "     print(sum(new_psi1[i]))\n",
        "  # Add new_psi1 to new_params\n",
        "  new_params[\"psi1\"] = new_psi1.tolist()\n",
        "\n",
        "  # Calculate new psi0\n",
        "  # Determine how many j positions we have in our input matrix\n",
        "  num_js = len(onehot_matrix[0]) - motif_length + 1\n",
        "  # Determine matrix dimensions and save our window sequences\n",
        "  X_ijmks = []\n",
        "  for i, ind_i in zip(onehot_matrix, range(len(onehot_matrix))):\n",
        "    # Iterate through the indeces for our lambda parameter\n",
        "    for ind_j in range(num_js):\n",
        "        # i[ind_j:ind_j+motif_length] is the base pair identities of the One-Hot encoded matrix within the window starting at j\n",
        "        X_ijmk = (i[ind_j:ind_j+motif_length]).tolist()\n",
        "        # Save each X_ijmk to the X_ijmks list for ease of access\n",
        "        X_ijmks.append(X_ijmk)\n",
        "  # Manipulate the posterior so it maches the X_ijmks list\n",
        "  manipulated_posterior = []\n",
        "  for i in posterior:\n",
        "    for j in i:\n",
        "      manipulated_posterior.append(j)\n",
        "  # Make an empty list numerators, that will contain all the X_ijmks multiplied by C_ij    \n",
        "  numerators = []\n",
        "  for ind_post, X_ijmk in zip(range(len(manipulated_posterior)), X_ijmks):\n",
        "    # Turn X_ijmk into an array\n",
        "    X_ijmk_array = np.array(X_ijmk)\n",
        "    # Multiply X_ijmk by 1 minus the posterior (C_ij)\n",
        "    numerator = X_ijmk_array * (1 - manipulated_posterior[ind_post])\n",
        "    # Add the multiplied window sequences to the list \"numerators\"\n",
        "    numerators.append(numerator)\n",
        "  numerator_before_normalization = np.array(numerators).sum(axis = 0)\n",
        "  new_psi0 = np.divide(numerator_before_normalization, (len(onehot_matrix)*(len(onehot_matrix[0]) - motif_length + 1 - 1)))\n",
        "  # Verify that new_psi0 rows sum to 1\n",
        "  print('The sums of each row in our new psi0 are:')\n",
        "  for i in range(len(new_psi0)):\n",
        "     print(sum(new_psi0[i]))\n",
        "  # Add new_psi1 to new_params\n",
        "  new_params[\"psi0\"] = new_psi0.tolist()\n",
        "  \n",
        "  # Save our new parameters as the output for the function\n",
        "  return new_params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4G4z6HyvUM1"
      },
      "source": [
        "Write a function to compute the **log likelihood**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHLSgbKV1HuR"
      },
      "source": [
        "def loglikelihood(onehot_matrix, params, posteriors, motif_length):\n",
        "  # Calculation for lambda_j term\n",
        "  # Make an empty list that holds the lambda_j multiplied by each row of the posterior\n",
        "  lambda_j_terms = []\n",
        "  for posterior in posteriors:\n",
        "    # Muliply each posterior row by lambda_j\n",
        "    one_lambda_j_term = (posterior * np.log(params['lambda_j'])).tolist()\n",
        "    # Add each row's product to the list\n",
        "    lambda_j_terms.append(one_lambda_j_term)\n",
        "  # Make another empty list to hold the sums for each row (2D > 1D matrix)\n",
        "  all_sums = []\n",
        "  for term in lambda_j_terms:\n",
        "    # Sum each row\n",
        "    one_sum = sum(term)\n",
        "    # Add each row sum to the list\n",
        "    all_sums.append(one_sum)\n",
        "  # Sum all the individual row sums for our lambda_j_term\n",
        "  lambda_j_term = sum(all_sums)\n",
        "\n",
        "  # Calculation for psi terms\n",
        "  # Determine how many j positions we have in our input matrix\n",
        "  num_js = len(onehot_matrix[0]) - motif_length + 1\n",
        "  # Determine matrix dimensions and save our window sequences\n",
        "  X_ijmks = []\n",
        "  for i, ind_i in zip(onehot_matrix, range(len(onehot_matrix))):\n",
        "    # Iterate through the indeces for our lambda parameter\n",
        "    for ind_j in range(num_js):\n",
        "        # i[ind_j:ind_j+motif_length] is the base pair identities of the One-Hot encoded matrix within the window starting at j\n",
        "        X_ijmk = (i[ind_j:ind_j+motif_length]).tolist()\n",
        "        # Save each X_ijmk to the X_ijmks list for ease of access\n",
        "        X_ijmks.append(X_ijmk)\n",
        "  # Manipulate the posterior so it maches the X_ijmks list\n",
        "  manipulated_posterior = []\n",
        "  for i in posteriors:\n",
        "    for j in i:\n",
        "      manipulated_posterior.append(j)\n",
        "  psi0_sums = []\n",
        "  psi1_sums = []\n",
        "  for ind_post, X_ijmk in zip(range(len(manipulated_posterior)), X_ijmks):\n",
        "    # Turn X_ijmk into an array\n",
        "    X_ijmk_array = np.array(X_ijmk)\n",
        "    one_psi0_sum = X_ijmk_array * ((1 - manipulated_posterior[ind_post])*np.log(params['psi0']))\n",
        "    one_psi1_sum = X_ijmk_array * (manipulated_posterior[ind_post]*np.log(params['psi1']))\n",
        "    psi0_sums.append(one_psi0_sum)\n",
        "    psi1_sums.append(one_psi1_sum)\n",
        "  psi0_sums_aray = np.array(psi0_sums)\n",
        "  psi1_sums_aray = np.array(psi1_sums)\n",
        "  psi0_term = psi0_sums_aray.sum()\n",
        "  psi1_term = psi1_sums_aray.sum()\n",
        "\n",
        "  # Calculation for entropy term\n",
        "  entropy_term = (posteriors * np.log(posteriors)).sum()\n",
        "\n",
        "  # Calculate and return log likelihood\n",
        "  llh = (lambda_j_term + psi1_term + psi0_term) - entropy_term\n",
        "  return llh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzlbCRTbFXVQ"
      },
      "source": [
        "Run the EM algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbdDUvC9K7Ou"
      },
      "source": [
        "Here, the EM algorithm is presented as a function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhO9GqWsCSB4"
      },
      "source": [
        "def run_em(initial_params, num_iterations, seq_data, motif_length):\n",
        "  # Determine sequence length\n",
        "  seq_len = len(seq_data[0])\n",
        "  # Create an empty list that will contain the log likelihoods for plotting later\n",
        "  loglikelihoods = []\n",
        "  for i in range(1, num_iterations+1):\n",
        "    # Keep track of iteration number\n",
        "    print(f'Iteration #{i}')\n",
        "    if i == 1:\n",
        "      # Should use randomly initialized parameters\n",
        "      params = initial_params\n",
        "    else:\n",
        "      # Use parameters from the last EM implementation\n",
        "      params = new_params\n",
        "    # Run E-step to calculate posteriors\n",
        "    my_posterior = E_step(params, seq_data, seq_len, motif_length)\n",
        "    # Calculate log likelihood \n",
        "    llh = loglikelihood(seq_data, params, my_posterior, motif_length)\n",
        "    # Add log likelihood to the loglikelihoods list \n",
        "    loglikelihoods.append(llh)\n",
        "    # View log likelihood after each iteration(we should see convergence)\n",
        "    print(llh)\n",
        "    # Run M-step to further optimize parameters using new posterior from E-step\n",
        "    new_params = M_step(seq_data, my_posterior, motif_length)\n",
        "    # Return list of log likelihoods \n",
        "  return loglikelihoods"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4WjUXuyLBbg"
      },
      "source": [
        "Here, the EM algorithm is presented as code, but not a function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1af_j4kiOZti"
      },
      "source": [
        "# Create an empty list that will contain the log likelihoods for plotting later\n",
        "loglikelihoods = []\n",
        "\n",
        "# Run EM\n",
        "for i in range(1, num_iterations+1):\n",
        "  # Keep track of iteration number\n",
        "  print(f'Iteration #{i}')\n",
        "  if i == 1:\n",
        "    # Randomly initialize parameters for the first iteration\n",
        "    params = initialize_random_params(seq_len, motif_length)\n",
        "  else:\n",
        "    # Use parameters from the last EM implementation\n",
        "    params = new_params\n",
        "  # Run E-step to calculate posteriors\n",
        "  my_posterior = E_step(params, seq_data, seq_len, motif_length)\n",
        "  # Calculate log likelihood \n",
        "  llh = loglikelihood(seq_data, params, my_posterior, motif_length)\n",
        "  # Add log likelihood to the loglikelihoods list \n",
        "  loglikelihoods.append(llh)\n",
        "  # View log likelihood after each iteration(we should see convergence)\n",
        "  print(llh)\n",
        "  # Run M-step to further optimize parameters using new posterior from E-step\n",
        "  new_params = M_step(seq_data, my_posterior, motif_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9I1WRWsu6_V3"
      },
      "source": [
        "# **Run Experiments on EM Algorithm Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XNRby2I804q"
      },
      "source": [
        "Here, we will answer the questions to Assignment 1 Part 3 regarding our updated EM algorithm model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QATNfYSQ7uJS"
      },
      "source": [
        "## 1. Plot the log likelihood as a function of EM iteration, for 20 iterations, for 5 different random initializations of the model parameter. Does the log likelihood monotonically increase every iteration of every initialization?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bsGW5aMGx8W"
      },
      "source": [
        "Assign variables for Question 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdALivXoG0Q6"
      },
      "source": [
        "# Set the number of EM iterations\n",
        "num_iterations = 20\n",
        "\n",
        "# Sequence data used\n",
        "seq_data = my_ohe_sequence_padded\n",
        "\n",
        "# Length of the motif\n",
        "motif_length = 18"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jszKZogYGoI5"
      },
      "source": [
        "Run our EM using five different parameter initializations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGw8UtYbDwRm",
        "outputId": "98b820b4-b674-4531-b63d-009ae2d9bc07"
      },
      "source": [
        "np.random.seed(1)\n",
        "initial_params_1 = initialize_random_params(seq_len, motif_length)\n",
        "np.random.seed(2)\n",
        "initial_params_2 = initialize_random_params(seq_len, motif_length)\n",
        "np.random.seed(3)\n",
        "initial_params_3 = initialize_random_params(seq_len, motif_length)\n",
        "np.random.seed(4)\n",
        "initial_params_4 = initialize_random_params(seq_len, motif_length)\n",
        "np.random.seed(5)\n",
        "initial_params_5 = initialize_random_params(seq_len, motif_length)\n",
        "\n",
        "\n",
        "# Create lists that will contain the log likelihoods for plotting\n",
        "rand_init_1 = run_em(initial_params_1, num_iterations, seq_data, motif_length)\n",
        "rand_init_2 = run_em(initial_params_2, num_iterations, seq_data, motif_length)\n",
        "rand_init_3 = run_em(initial_params_3, num_iterations, seq_data, motif_length)\n",
        "rand_init_4 = run_em(initial_params_4, num_iterations, seq_data, motif_length)\n",
        "rand_init_5 = run_em(initial_params_5, num_iterations, seq_data, motif_length)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration #1\n",
            "-256843.00949631058\n",
            "The sum of our new lambda_j is: 1.0\n",
            "The sums of each row in our new psi1 are:\n",
            "1.0\n",
            "0.9999999999999999\n",
            "0.9999999999999998\n",
            "1.0\n",
            "0.9999999999999998\n",
            "0.9999999999999998\n",
            "0.9999999999999998\n",
            "1.0\n",
            "1.0000000000000004\n",
            "0.9999999999999998\n",
            "1.0000000000000002\n",
            "1.0\n",
            "1.0\n",
            "1.0\n",
            "0.9999999999999998\n",
            "1.0\n",
            "0.9999999999999997\n",
            "0.9999999999999999\n",
            "The sums of each row in our new psi0 are:\n",
            "1.0\n",
            "0.9999999999999999\n",
            "0.9999999999999999\n",
            "0.9999999999999997\n",
            "1.0\n",
            "0.9999999999999999\n",
            "1.0\n",
            "1.0\n",
            "0.9999999999999999\n",
            "0.9999999999999999\n",
            "0.9999999999999999\n",
            "1.0\n",
            "0.9999999999999999\n",
            "1.0000000000000002\n",
            "0.9999999999999999\n",
            "0.9999999999999999\n",
            "0.9999999999999999\n",
            "0.9999999999999999\n",
            "Iteration #2\n",
            "-188982.1221878149\n",
            "The sum of our new lambda_j is: 0.9999999999999997\n",
            "The sums of each row in our new psi1 are:\n",
            "0.9999999999999996\n",
            "0.9999999999999996\n",
            "0.9999999999999989\n",
            "0.9999999999999994\n",
            "0.9999999999999998\n",
            "1.0\n",
            "0.9999999999999997\n",
            "1.0000000000000002\n",
            "1.0000000000000002\n",
            "1.0\n",
            "0.9999999999999996\n",
            "1.0\n",
            "1.0\n",
            "0.9999999999999997\n",
            "0.9999999999999989\n",
            "0.9999999999999982\n",
            "1.0\n",
            "0.9999999999999994\n",
            "The sums of each row in our new psi0 are:\n",
            "1.0000000000000002\n",
            "1.0000000000000004\n",
            "1.0000000000000004\n",
            "1.0000000000000004\n",
            "1.0000000000000004\n",
            "1.0000000000000007\n",
            "1.0\n",
            "1.0000000000000007\n",
            "1.0000000000000002\n",
            "1.0000000000000004\n",
            "1.0000000000000004\n",
            "1.0000000000000004\n",
            "1.0000000000000009\n",
            "1.0000000000000004\n",
            "1.0000000000000004\n",
            "1.0000000000000004\n",
            "1.0000000000000007\n",
            "1.0000000000000004\n",
            "Iteration #3\n",
            "-186437.7919685305\n",
            "The sum of our new lambda_j is: 1.0000000000000002\n",
            "The sums of each row in our new psi1 are:\n",
            "1.0000000000000002\n",
            "0.9999999999999998\n",
            "0.9999999999999999\n",
            "1.0000000000000004\n",
            "0.9999999999999999\n",
            "1.0000000000000009\n",
            "0.9999999999999996\n",
            "0.9999999999999996\n",
            "0.9999999999999998\n",
            "0.9999999999999998\n",
            "0.9999999999999984\n",
            "0.9999999999999997\n",
            "0.9999999999999989\n",
            "1.000000000000001\n",
            "1.0000000000000007\n",
            "1.0000000000000002\n",
            "0.9999999999999997\n",
            "0.999999999999999\n",
            "The sums of each row in our new psi0 are:\n",
            "0.9999999999999994\n",
            "0.9999999999999993\n",
            "0.9999999999999992\n",
            "0.9999999999999998\n",
            "0.9999999999999993\n",
            "0.9999999999999994\n",
            "0.9999999999999996\n",
            "0.9999999999999991\n",
            "0.9999999999999997\n",
            "0.9999999999999994\n",
            "0.9999999999999994\n",
            "0.9999999999999991\n",
            "0.9999999999999994\n",
            "0.9999999999999996\n",
            "0.9999999999999991\n",
            "0.9999999999999994\n",
            "0.9999999999999992\n",
            "0.9999999999999994\n",
            "Iteration #4\n",
            "-186279.4508175166\n",
            "The sum of our new lambda_j is: 1.0000000000000002\n",
            "The sums of each row in our new psi1 are:\n",
            "1.0000000000000013\n",
            "0.9999999999999996\n",
            "1.0000000000000007\n",
            "0.9999999999999998\n",
            "0.9999999999999991\n",
            "0.9999999999999996\n",
            "0.9999999999999996\n",
            "1.0000000000000004\n",
            "0.9999999999999989\n",
            "0.9999999999999988\n",
            "0.9999999999999992\n",
            "1.0\n",
            "0.9999999999999996\n",
            "0.9999999999999988\n",
            "1.0000000000000007\n",
            "1.0000000000000002\n",
            "1.0000000000000007\n",
            "0.9999999999999984\n",
            "The sums of each row in our new psi0 are:\n",
            "1.0000000000000004\n",
            "1.0000000000000009\n",
            "1.0000000000000004\n",
            "1.0000000000000007\n",
            "1.0000000000000004\n",
            "1.0000000000000007\n",
            "1.0000000000000002\n",
            "1.0000000000000004\n",
            "1.0000000000000004\n",
            "1.000000000000001\n",
            "1.0000000000000007\n",
            "1.000000000000001\n",
            "1.0000000000000007\n",
            "1.0000000000000004\n",
            "1.0000000000000009\n",
            "1.0000000000000007\n",
            "1.0000000000000007\n",
            "1.0000000000000007\n",
            "Iteration #5\n",
            "-186245.98850841698\n",
            "The sum of our new lambda_j is: 0.9999999999999998\n",
            "The sums of each row in our new psi1 are:\n",
            "1.0000000000000009\n",
            "1.0000000000000002\n",
            "0.9999999999999999\n",
            "1.0\n",
            "0.9999999999999993\n",
            "0.9999999999999996\n",
            "1.0000000000000004\n",
            "0.9999999999999989\n",
            "1.0000000000000002\n",
            "0.9999999999999991\n",
            "0.9999999999999998\n",
            "1.0\n",
            "0.9999999999999996\n",
            "0.9999999999999997\n",
            "0.9999999999999988\n",
            "1.0000000000000013\n",
            "0.9999999999999991\n",
            "1.0000000000000004\n",
            "The sums of each row in our new psi0 are:\n",
            "1.0000000000000009\n",
            "1.0000000000000009\n",
            "1.000000000000001\n",
            "1.0000000000000013\n",
            "1.000000000000001\n",
            "1.000000000000001\n",
            "1.000000000000001\n",
            "1.0000000000000013\n",
            "1.0000000000000007\n",
            "1.000000000000001\n",
            "1.0000000000000009\n",
            "1.0000000000000009\n",
            "1.000000000000001\n",
            "1.0000000000000013\n",
            "1.0000000000000009\n",
            "1.0000000000000013\n",
            "1.0000000000000009\n",
            "1.0000000000000009\n",
            "Iteration #6\n",
            "-186243.14121480988\n",
            "The sum of our new lambda_j is: 0.9999999999999997\n",
            "The sums of each row in our new psi1 are:\n",
            "0.999999999999999\n",
            "0.9999999999999992\n",
            "0.9999999999999996\n",
            "0.9999999999999996\n",
            "0.9999999999999989\n",
            "0.9999999999999988\n",
            "0.9999999999999987\n",
            "1.0000000000000007\n",
            "0.9999999999999993\n",
            "0.9999999999999988\n",
            "0.9999999999999992\n",
            "1.0000000000000004\n",
            "0.9999999999999998\n",
            "0.9999999999999996\n",
            "1.0\n",
            "0.9999999999999989\n",
            "1.0000000000000013\n",
            "0.9999999999999991\n",
            "The sums of each row in our new psi0 are:\n",
            "1.0000000000000009\n",
            "1.0000000000000013\n",
            "1.0000000000000009\n",
            "1.000000000000001\n",
            "1.000000000000001\n",
            "1.000000000000001\n",
            "1.000000000000001\n",
            "1.000000000000001\n",
            "1.0000000000000013\n",
            "1.000000000000001\n",
            "1.0000000000000013\n",
            "1.0000000000000009\n",
            "1.0000000000000013\n",
            "1.0000000000000007\n",
            "1.0000000000000013\n",
            "1.0000000000000013\n",
            "1.000000000000001\n",
            "1.000000000000001\n",
            "Iteration #7\n",
            "-186244.69493305834\n",
            "The sum of our new lambda_j is: 1.0000000000000004\n",
            "The sums of each row in our new psi1 are:\n",
            "0.9999999999999997\n",
            "0.9999999999999998\n",
            "0.9999999999999994\n",
            "0.9999999999999999\n",
            "0.9999999999999998\n",
            "0.9999999999999984\n",
            "1.0000000000000004\n",
            "0.9999999999999993\n",
            "1.0\n",
            "0.9999999999999991\n",
            "1.0\n",
            "0.9999999999999997\n",
            "1.0\n",
            "1.0000000000000004\n",
            "0.9999999999999999\n",
            "0.9999999999999991\n",
            "0.9999999999999983\n",
            "0.9999999999999996\n",
            "The sums of each row in our new psi0 are:\n",
            "0.9999999999999998\n",
            "0.9999999999999998\n",
            "1.0\n",
            "0.9999999999999998\n",
            "1.0\n",
            "0.9999999999999998\n",
            "1.0\n",
            "1.0\n",
            "0.9999999999999999\n",
            "0.9999999999999998\n",
            "1.0\n",
            "0.9999999999999999\n",
            "0.9999999999999996\n",
            "0.9999999999999996\n",
            "1.0\n",
            "0.9999999999999997\n",
            "1.0\n",
            "1.0000000000000002\n",
            "Iteration #8\n",
            "-186247.294595789\n",
            "The sum of our new lambda_j is: 1.0\n",
            "The sums of each row in our new psi1 are:\n",
            "0.9999999999999987\n",
            "0.9999999999999998\n",
            "0.9999999999999997\n",
            "0.9999999999999992\n",
            "0.999999999999999\n",
            "0.9999999999999986\n",
            "0.9999999999999996\n",
            "0.9999999999999986\n",
            "0.9999999999999996\n",
            "0.9999999999999998\n",
            "0.9999999999999999\n",
            "0.9999999999999993\n",
            "0.9999999999999997\n",
            "0.9999999999999993\n",
            "0.9999999999999999\n",
            "0.9999999999999992\n",
            "0.9999999999999984\n",
            "0.9999999999999997\n",
            "The sums of each row in our new psi0 are:\n",
            "1.0\n",
            "0.9999999999999998\n",
            "1.0\n",
            "1.0\n",
            "0.9999999999999996\n",
            "1.0\n",
            "1.0\n",
            "0.9999999999999998\n",
            "1.0000000000000002\n",
            "1.0\n",
            "1.0000000000000002\n",
            "0.9999999999999999\n",
            "1.0\n",
            "1.0\n",
            "1.0000000000000004\n",
            "1.0\n",
            "0.9999999999999997\n",
            "1.0000000000000002\n",
            "Iteration #9\n",
            "-186249.66551722083\n",
            "The sum of our new lambda_j is: 1.0000000000000002\n",
            "The sums of each row in our new psi1 are:\n",
            "0.9999999999999978\n",
            "0.9999999999999987\n",
            "0.9999999999999994\n",
            "0.9999999999999986\n",
            "0.9999999999999989\n",
            "0.9999999999999993\n",
            "0.9999999999999984\n",
            "1.0000000000000004\n",
            "0.9999999999999994\n",
            "0.9999999999999996\n",
            "0.9999999999999997\n",
            "0.9999999999999998\n",
            "0.9999999999999996\n",
            "0.9999999999999996\n",
            "0.9999999999999988\n",
            "0.9999999999999989\n",
            "0.9999999999999984\n",
            "0.9999999999999983\n",
            "The sums of each row in our new psi0 are:\n",
            "1.000000000000001\n",
            "1.000000000000001\n",
            "1.000000000000001\n",
            "1.000000000000001\n",
            "1.000000000000001\n",
            "1.0000000000000016\n",
            "1.0000000000000016\n",
            "1.0000000000000013\n",
            "1.000000000000001\n",
            "1.0000000000000009\n",
            "1.0000000000000007\n",
            "1.0000000000000013\n",
            "1.0000000000000013\n",
            "1.000000000000001\n",
            "1.000000000000001\n",
            "1.000000000000001\n",
            "1.000000000000001\n",
            "1.0000000000000013\n",
            "Iteration #10\n",
            "-186251.52448882736\n",
            "The sum of our new lambda_j is: 1.0000000000000002\n",
            "The sums of each row in our new psi1 are:\n",
            "0.9999999999999987\n",
            "0.9999999999999993\n",
            "0.9999999999999996\n",
            "0.9999999999999993\n",
            "0.9999999999999998\n",
            "0.9999999999999994\n",
            "0.9999999999999993\n",
            "0.9999999999999987\n",
            "1.0000000000000004\n",
            "0.9999999999999998\n",
            "0.9999999999999993\n",
            "0.9999999999999993\n",
            "1.0000000000000004\n",
            "0.9999999999999993\n",
            "0.9999999999999974\n",
            "0.9999999999999993\n",
            "0.9999999999999987\n",
            "1.0000000000000002\n",
            "The sums of each row in our new psi0 are:\n",
            "1.0000000000000009\n",
            "1.0000000000000004\n",
            "1.0000000000000002\n",
            "1.0000000000000002\n",
            "1.0000000000000004\n",
            "1.0000000000000004\n",
            "1.0000000000000007\n",
            "1.0000000000000007\n",
            "1.0000000000000004\n",
            "1.0000000000000007\n",
            "1.0000000000000007\n",
            "1.0000000000000004\n",
            "1.0000000000000004\n",
            "1.0000000000000004\n",
            "1.0000000000000004\n",
            "1.0000000000000002\n",
            "1.0000000000000007\n",
            "1.0000000000000002\n",
            "Iteration #11\n",
            "-186252.8694211816\n",
            "The sum of our new lambda_j is: 1.0000000000000002\n",
            "The sums of each row in our new psi1 are:\n",
            "0.9999999999999977\n",
            "0.9999999999999989\n",
            "0.9999999999999982\n",
            "0.999999999999999\n",
            "0.9999999999999983\n",
            "0.9999999999999989\n",
            "0.9999999999999993\n",
            "0.9999999999999989\n",
            "1.0000000000000002\n",
            "0.9999999999999994\n",
            "0.9999999999999996\n",
            "0.9999999999999996\n",
            "0.9999999999999993\n",
            "0.9999999999999981\n",
            "0.9999999999999976\n",
            "0.9999999999999982\n",
            "1.0\n",
            "0.9999999999999998\n",
            "The sums of each row in our new psi0 are:\n",
            "1.0000000000000009\n",
            "1.0000000000000004\n",
            "1.0000000000000004\n",
            "1.0000000000000007\n",
            "1.0000000000000009\n",
            "1.0000000000000004\n",
            "1.0000000000000009\n",
            "1.0000000000000009\n",
            "1.0000000000000009\n",
            "1.0000000000000002\n",
            "1.0000000000000007\n",
            "1.0000000000000004\n",
            "1.0000000000000007\n",
            "1.0000000000000009\n",
            "1.0000000000000007\n",
            "1.0000000000000007\n",
            "1.0000000000000009\n",
            "1.0000000000000007\n",
            "Iteration #12\n",
            "-186253.8023128262\n",
            "The sum of our new lambda_j is: 0.9999999999999996\n",
            "The sums of each row in our new psi1 are:\n",
            "0.9999999999999998\n",
            "1.0\n",
            "0.9999999999999993\n",
            "0.9999999999999996\n",
            "1.0000000000000004\n",
            "1.0000000000000009\n",
            "0.9999999999999996\n",
            "1.0000000000000013\n",
            "1.0\n",
            "0.9999999999999996\n",
            "1.0000000000000004\n",
            "0.9999999999999998\n",
            "0.9999999999999998\n",
            "1.0000000000000009\n",
            "1.0\n",
            "1.000000000000001\n",
            "0.9999999999999999\n",
            "1.0000000000000004\n",
            "The sums of each row in our new psi0 are:\n",
            "1.0000000000000009\n",
            "1.0000000000000007\n",
            "1.0000000000000004\n",
            "1.0000000000000007\n",
            "1.0000000000000009\n",
            "1.0000000000000002\n",
            "1.0000000000000002\n",
            "1.0000000000000004\n",
            "1.0000000000000004\n",
            "1.0000000000000007\n",
            "1.0000000000000004\n",
            "1.0000000000000004\n",
            "1.0000000000000007\n",
            "1.0000000000000004\n",
            "1.0000000000000004\n",
            "1.0000000000000004\n",
            "1.0000000000000004\n",
            "1.0000000000000007\n",
            "Iteration #13\n",
            "-186254.43294756144\n",
            "The sum of our new lambda_j is: 0.9999999999999999\n",
            "The sums of each row in our new psi1 are:\n",
            "1.0000000000000002\n",
            "0.9999999999999994\n",
            "1.0000000000000007\n",
            "0.9999999999999999\n",
            "1.0\n",
            "0.9999999999999991\n",
            "0.999999999999999\n",
            "0.9999999999999998\n",
            "0.9999999999999984\n",
            "0.9999999999999998\n",
            "0.9999999999999996\n",
            "1.0000000000000002\n",
            "0.9999999999999999\n",
            "0.9999999999999993\n",
            "0.9999999999999991\n",
            "0.9999999999999994\n",
            "0.9999999999999996\n",
            "0.9999999999999989\n",
            "The sums of each row in our new psi0 are:\n",
            "1.0\n",
            "1.0\n",
            "1.0000000000000002\n",
            "1.0\n",
            "1.0000000000000004\n",
            "1.0\n",
            "0.9999999999999999\n",
            "1.0000000000000002\n",
            "1.0000000000000002\n",
            "1.0\n",
            "1.0\n",
            "1.0000000000000002\n",
            "1.0000000000000002\n",
            "1.0000000000000002\n",
            "1.0\n",
            "1.0\n",
            "1.0000000000000002\n",
            "1.0\n",
            "Iteration #14\n",
            "-186254.8526090714\n",
            "The sum of our new lambda_j is: 1.0\n",
            "The sums of each row in our new psi1 are:\n",
            "0.9999999999999991\n",
            "0.9999999999999998\n",
            "1.0\n",
            "1.0\n",
            "0.9999999999999991\n",
            "1.0000000000000009\n",
            "0.9999999999999996\n",
            "0.9999999999999991\n",
            "0.9999999999999992\n",
            "0.9999999999999998\n",
            "1.0\n",
            "0.999999999999999\n",
            "0.9999999999999993\n",
            "0.999999999999999\n",
            "0.9999999999999994\n",
            "0.9999999999999996\n",
            "1.0000000000000007\n",
            "0.999999999999999\n",
            "The sums of each row in our new psi0 are:\n",
            "1.000000000000001\n",
            "1.0000000000000009\n",
            "1.0000000000000004\n",
            "1.0000000000000009\n",
            "1.0000000000000009\n",
            "1.0000000000000009\n",
            "1.0000000000000009\n",
            "1.0000000000000009\n",
            "1.0000000000000009\n",
            "1.0000000000000007\n",
            "1.0000000000000009\n",
            "1.0000000000000009\n",
            "1.0000000000000007\n",
            "1.0000000000000009\n",
            "1.0000000000000004\n",
            "1.0000000000000004\n",
            "1.0000000000000007\n",
            "1.0000000000000009\n",
            "Iteration #15\n",
            "-186255.1289532265\n",
            "The sum of our new lambda_j is: 0.9999999999999999\n",
            "The sums of each row in our new psi1 are:\n",
            "0.9999999999999994\n",
            "1.0000000000000004\n",
            "1.0000000000000007\n",
            "0.9999999999999987\n",
            "0.9999999999999996\n",
            "1.0\n",
            "1.0000000000000004\n",
            "0.9999999999999993\n",
            "0.9999999999999993\n",
            "0.9999999999999998\n",
            "1.0\n",
            "1.0000000000000007\n",
            "0.9999999999999998\n",
            "0.9999999999999997\n",
            "0.9999999999999998\n",
            "0.9999999999999997\n",
            "1.0000000000000004\n",
            "0.9999999999999997\n",
            "The sums of each row in our new psi0 are:\n",
            "1.000000000000001\n",
            "1.0000000000000009\n",
            "1.0000000000000016\n",
            "1.000000000000001\n",
            "1.000000000000001\n",
            "1.000000000000001\n",
            "1.0000000000000013\n",
            "1.000000000000001\n",
            "1.0000000000000013\n",
            "1.0000000000000009\n",
            "1.0000000000000004\n",
            "1.0000000000000013\n",
            "1.0000000000000004\n",
            "1.0000000000000004\n",
            "1.0000000000000009\n",
            "1.000000000000001\n",
            "1.000000000000001\n",
            "1.0000000000000009\n",
            "Iteration #16\n",
            "-186255.30953323847\n",
            "The sum of our new lambda_j is: 1.0\n",
            "The sums of each row in our new psi1 are:\n",
            "1.0000000000000002\n",
            "0.9999999999999996\n",
            "0.9999999999999999\n",
            "0.9999999999999979\n",
            "0.9999999999999994\n",
            "0.9999999999999997\n",
            "1.0000000000000002\n",
            "1.0\n",
            "1.0000000000000002\n",
            "1.0\n",
            "0.9999999999999999\n",
            "1.0000000000000007\n",
            "1.0000000000000004\n",
            "0.9999999999999997\n",
            "0.9999999999999997\n",
            "0.9999999999999991\n",
            "0.9999999999999989\n",
            "1.0000000000000004\n",
            "The sums of each row in our new psi0 are:\n",
            "1.000000000000001\n",
            "1.000000000000001\n",
            "1.0000000000000013\n",
            "1.0000000000000013\n",
            "1.0000000000000013\n",
            "1.000000000000001\n",
            "1.0000000000000013\n",
            "1.000000000000001\n",
            "1.0000000000000013\n",
            "1.000000000000001\n",
            "1.0000000000000013\n",
            "1.000000000000001\n",
            "1.0000000000000016\n",
            "1.0000000000000013\n",
            "1.0000000000000009\n",
            "1.000000000000001\n",
            "1.0000000000000013\n",
            "1.0000000000000013\n",
            "Iteration #17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGy4MFULRUtv"
      },
      "source": [
        "Make the graph of the log likelihood after each iteration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxlLrJufRYTI"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set number of iterations\n",
        "iterations = 20\n",
        "\n",
        "# Create list containing iteration number (for x-axis labels)\n",
        "num_iterations = []\n",
        "# Use range (1, iterations+1) since Python uses 0-based indexing\n",
        "for i in range(1, iterations+1):\n",
        "  num_iterations.append(i)\n",
        "\n",
        "# Make a plot where the x-axis is the number of iterations\n",
        "# and the y-axis contains the log likelihoods\n",
        "plt.plot(num_iterations, rand_init_1, label = \"rand_init_1\")\n",
        "plt.plot(num_iterations, rand_init_2, label = \"rand_init_2\")\n",
        "plt.plot(num_iterations, rand_init_3, label = \"rand_init_3\")\n",
        "plt.plot(num_iterations, rand_init_4, label = \"rand_init_4\")\n",
        "plt.plot(num_iterations, rand_init_5, label = \"rand_init_5\")\n",
        "\n",
        "# Assign axis titles, plot titles, and legend\n",
        "plt.title('Log Likelihood as a Function of EM Iteration')\n",
        "plt.xlabel('Number of EM Iterations')\n",
        "plt.ylabel('Log Likelihood')\n",
        "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "\n",
        "# Generate plot\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXIQCUDfnKYN"
      },
      "source": [
        "As we see above, the log likelihoods monotinically increase as expected and converge."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WO67ygHC76X4"
      },
      "source": [
        "## 2. Draw a sequence logo visualization of the foreground motif your model learns, $\\psi^{l}_{m, k}$. You could try LogoMaker, a Python library (https://logomaker.readthedocs.io/en/latest/). Alternatively, there are a number of web servers for doing this; you could draw samples from your foreground model, and input those drawn sequences into e.g. the WebLogo server (https://weblogo.berkeley.edu)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU_x1Agb8ySl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpV2tMRA9I2k"
      },
      "source": [
        "## 3. Now run your model using model random initializations. How do the model parameters $\\psi^{l}_{m, k}$ compare across runs? What about their log likelihoods?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPxQA-BW9RBd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ixs58dhD9WRZ"
      },
      "source": [
        "## 4. Plot a figure that shows the distribution over $C_{ij}$ for a few of the input sequences, and compare that (in the visualization) to the ground truth. How close was your model to predicting the real motif location?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEeQ51eY9cO_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHeUPqxu9nBr"
      },
      "source": [
        "## 5. Train your model using 80% of the data, holding out the remaining 20%. Evaluate the log likelihood of your held out data using the model you implemented in this assignment, and compare it to the log likelihood from the simple latent model we used in class, using the same training/held out data. Which one is better?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWZ_T8zj9qMr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17Ed0I_N9s9Z"
      },
      "source": [
        "## 6. Train your model on the atgcsequences.txt file (that had a GC-rich region embedded between two flanking AT-rich regions). Does the model work better?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq80KKxQ-Ed3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkc5IO2o-E6i"
      },
      "source": [
        "## 7. The original training set in sequence.padded.txt has 357 sequences. Randomly sample another 357 sequences of the same length (just from a simple generator, that produces each base at equal frequency) and train the model with all data. Does it still recover the same motif? What if you add 3000 noisy sequences?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EQJ9k8E-7T0"
      },
      "source": [
        "Generate 357 sequences of the same length that produces each base at equal frequency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMYZPCktUaAg"
      },
      "source": [
        "import random\n",
        "\n",
        "# Number of sequences to generate\n",
        "seqs = 357\n",
        "# The minimum sequence length\n",
        "min = 40\n",
        "# The maximum sequence length\n",
        "max = 40\n",
        "# GC-content as a proportion\n",
        "gc = 0.5\n",
        "\n",
        "assert(seqs > 0)\n",
        "assert(min > 0)\n",
        "assert(max >= min)\n",
        "assert(gc >= 0 and gc <= 1)\n",
        "\n",
        "# Use probabilities for random sequence generation\n",
        "# This does not guarantee that all bases are present at equal frequency\n",
        "# But this means the sequence length does not have to be divisible by 4\n",
        "# And base pair frequencies are close to equal\n",
        "my_seqs = []\n",
        "for i in range(seqs):\n",
        "    l = random.randint(min, max)\n",
        "    seq = []\n",
        "    for j in range(l):\n",
        "        r = random.random()\n",
        "        if r < gc:\n",
        "            r = random.random()\n",
        "            if r < 0.5: seq.append('G')\n",
        "            else:       seq.append('C')\n",
        "        else:\n",
        "            r = random.random()\n",
        "            if r < 0.5: seq.append('A')\n",
        "            else:       seq.append('T')\n",
        "    my_seqs.append(''.join(seq))\n",
        "\n",
        "print(my_seqs)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}