{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vhaghani26/BST_227_Code/blob/main/Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEB6Jbmxr9P7"
      },
      "source": [
        "# **The EM Algorithm for a more complex sequence model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zDlf51Mr6wp"
      },
      "source": [
        "First, we need to import the modules we plan to use to run the code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yrbLTPNtux7"
      },
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puqdz-Cxsg4i"
      },
      "source": [
        "# **Download and Process Sequence Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9liLSAMwHEe"
      },
      "source": [
        "Set data file URL locations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "143x5QHNwKZg"
      },
      "source": [
        "# URL for at_gc_sequences.txt - this is a single sequence: ATTTAATATAAAATTTGGCCGCCATAAAAAAA\n",
        "at_gc_sequences_txt = 'https://ucdavis.box.com/shared/static/s8g6zx9vwxbbfdxdj2uqzhlvslc1jhsy.txt'\n",
        "# URL for sequence.padded.txt - the real binding site data\n",
        "sequence_padded_txt = 'https://ucdavis.box.com/shared/static/0cacx2xvn4ugxo9h21ci2ngesryigf43.txt'\n",
        "# URL for sequence.motiflocation.padded.txt - the location of the binding sites from sequence.padded.txt\n",
        "sequence_motiflocation_padded_txt = 'https://ucdavis.box.com/shared/static/gd0r12mdkhix86bo9ffbn3dy0fy0prmn.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdktorRL4uEj"
      },
      "source": [
        "Write a function to download and one-hot encoded the sequence data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ka8lwgcXZ5XF"
      },
      "source": [
        "# Function written by Chenxi Liu (slight modifications made)\n",
        "\n",
        "def get_sequence(url, categories=['A', 'C', 'G', 'T']):\n",
        "  # Send a GET request to a specified URL, categories=['A', 'C', 'G', 'T']):\n",
        "  r = requests.get(url)\n",
        "  # Convert sequence data to data frame\n",
        "  df = pd.read_csv(io.StringIO(r.text), sep=\" \", header=None)\n",
        "  # Turn the first sequence into a 2D array where each index is an independent array with a single base pair\n",
        "  s1 = np.array(list(str(df.to_numpy()[0, :][0])), dtype=object).reshape(-1, 1)\n",
        "\n",
        "  # Determine how many sequences there are in the text file\n",
        "  num_seqs = len(df)\n",
        "  # Assume all input sequences are equal length\n",
        "  # Determine how long each sequence is\n",
        "  seq_len = len(list(df.iloc[0, :].values)[0])\n",
        "  # Start to make a one-hot encoded 3D matrix for the seqeunces\n",
        "  # Not one-hot encoded yet, just zeroes \n",
        "  data = np.zeros((num_seqs, seq_len, len(categories)))\n",
        "  # Make a matrix repersenting each category ['A', 'C', 'G', 'T']\n",
        "  bp_counts = np.zeros((1, len(categories)))\n",
        "\n",
        "  # Encode categorical feautures in a one-hot numeric array\n",
        "  # Assign categories to be used\n",
        "  ohe = OneHotEncoder(sparse=False, categories=[np.array(categories, dtype=object)])\n",
        "  # Apply OneHotEncoder to example sequence\n",
        "  ohe.fit(s1)\n",
        "  \n",
        "  # Apply OneHotEncoder to all sequences\n",
        "  for ii in tqdm(range(num_seqs)):\n",
        "    s = list(str(df.to_numpy()[ii, :][0]))\n",
        "    s_a = np.array(s).reshape(-1, 1)\n",
        "    data[ii, :, :] = ohe.transform(s_a)\n",
        "  \n",
        "  # Count the number of each base in the sequence data\n",
        "  for ii in range(len(categories)):\n",
        "    bp_counts[0,ii] = np.sum(data[:,:,ii])\n",
        "  \n",
        "  # Return the one-hot encoded matrix (data),\n",
        "  # the counts for each base pair (bp_counts),\n",
        "  # the number of sequences (N),\n",
        "  # and the length of each sequence (L)\n",
        "  return data, bp_counts, num_seqs, seq_len                                                    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "od2WQCQrDDyv"
      },
      "source": [
        "Write a modified version of the above function that returns a randomly split training and test data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJGr38gKDNuE"
      },
      "source": [
        "# Function written by Chenxi Liu and Gerald Quon\n",
        "\n",
        "def get_sequence_traintest(url, categories=['A', 'C', 'G', 'T'], FRACTION_TRAINING=0.8):\n",
        "  # Send a GET request to a specified URL, categories=['A', 'C', 'G', 'T']):\n",
        "  r = requests.get(url)\n",
        "  # Convert sequence data to data frame\n",
        "  df = pd.read_csv(io.StringIO(r.text), sep=\" \", header=None)\n",
        "  # Turn the first sequence into a 2D array where each index is an independent array with a single base pair\n",
        "  s1 = np.array(list(str(df.to_numpy()[0, :][0])), dtype=object).reshape(-1, 1)\n",
        "\n",
        "  # Determine how many sequences there are in the text file\n",
        "  m = len(df)\n",
        "  # Assume all input sequences are equal length\n",
        "  # Determine how long each sequence is\n",
        "  sequence_len = len(list(df.iloc[0, :].values)[0])\n",
        "  # Start to make a one-hot encoded 3D matrix for the seqeunces\n",
        "  # Not one-hot encoded yet, just zeroes \n",
        "  data = np.zeros((m, sequence_len, len(categories)))\n",
        "  # Make a matrix repersenting each category ['A', 'C', 'G', 'T'] for the training set\n",
        "  bp_counts_train = np.zeros((1, len(categories)))\n",
        "  # Make a matrix repersenting each category ['A', 'C', 'G', 'T'] for the test set\n",
        "  bp_counts_test = np.zeros((1, len(categories)))\n",
        "\n",
        "  # Encode categorical feautures in a one-hot numeric array\n",
        "  # Assign categories to be used\n",
        "  ohe = OneHotEncoder(sparse=False, categories=[np.array(categories, dtype=object)])\n",
        "  # Apply OneHotEncoder to example sequence\n",
        "  ohe.fit(s1)\n",
        "\n",
        "  # Apply OneHotEncoder to all sequences\n",
        "  for ii in tqdm(range(m)):\n",
        "    s = list(str(df.to_numpy()[ii, :][0]))\n",
        "    s_a = np.array(s).reshape(-1, 1)\n",
        "    data[ii, :, :] = ohe.transform(s_a)\n",
        "\n",
        "  # Randomly permute rows of matrix\n",
        "  np.random.shuffle(data)\n",
        "\n",
        "  # Split data into training and text data\n",
        "  train_indices = np.arange(start=0,stop=round(FRACTION_TRAINING*data.shape[0]))\n",
        "  test_indices = np.arange(start=round(FRACTION_TRAINING*data.shape[0]), stop=data.shape[0])\n",
        "  \n",
        "  # Count the number of each base in the test and train sets\n",
        "  for ii in range(len(categories)):\n",
        "    bp_counts_train[0,ii] = np.sum(data[train_indices,:,ii])\n",
        "    bp_counts_test[0,ii] = np.sum(data[test_indices,:,ii])\n",
        "  \n",
        "  # Return the base pair counts for the test and train sets\n",
        "  return bp_counts_train, bp_counts_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5H6PrulrH9ap"
      },
      "source": [
        "Load in the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxoFtgmPH_Ev",
        "outputId": "8aa58045-faf7-4ab5-aab1-e02c95ee9238"
      },
      "source": [
        "# Implement get_sequence()\n",
        "# The variable my_ohe_sequence_padded corresponds to the one-hot encoded matrices that represent the sequence data\n",
        "# The variable my_sequence_padded_bp_counts is the base pair counts for the input sequence data\n",
        "# The variable my_sequence_padded_num_seqs returns the number of sequences in the sequence file\n",
        "# sequence_padded_txt is the variable name containing the URL defined at the beginning\n",
        "my_ohe_sequence_padded, my_sequence_padded_bp_counts, my_sequence_padded_num_seqs, my_sequence_padded_seq_len = get_sequence(sequence_padded_txt, categories=['A', 'C', 'G', 'T'])\n",
        "\n",
        "# Following similar notation above, we can implement get_sequence() for the at_gc_sequences_text data\n",
        "my_ohe_at_gc_sequences, my_at_gc_bp_counts, my_at_gc_num_seqs, my_at_gc_seq_len = get_sequence(at_gc_sequences_txt, categories=['A', 'C', 'G', 'T'])\n",
        "\n",
        "# Now randomly split the sequence_padded_txt into a training vs test set\n",
        "sequence_padded_train_bp_counts, sequence_padded_test_bp_counts = get_sequence_traintest(sequence_padded_txt, categories=['A', 'C', 'G', 'T'])\n",
        "\n",
        "# Get the locations of the motifs for the sequence.padded.txt file\n",
        "sequence_padded_motifs = pd.read_csv(io.StringIO(requests.get(sequence_motiflocation_padded_txt).text), sep=\",\", header=None).to_numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 357/357 [00:00<00:00, 2394.71it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 366.22it/s]\n",
            "100%|██████████| 357/357 [00:00<00:00, 2314.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[1. 0. 0. 0.]\n",
            "  [0. 0. 0. 1.]\n",
            "  [1. 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 1. 0. 0.]\n",
            "  [0. 0. 1. 0.]\n",
            "  [0. 0. 0. 1.]]\n",
            "\n",
            " [[0. 1. 0. 0.]\n",
            "  [1. 0. 0. 0.]\n",
            "  [0. 0. 0. 1.]\n",
            "  ...\n",
            "  [0. 1. 0. 0.]\n",
            "  [1. 0. 0. 0.]\n",
            "  [0. 0. 0. 1.]]\n",
            "\n",
            " [[1. 0. 0. 0.]\n",
            "  [0. 0. 1. 0.]\n",
            "  [0. 1. 0. 0.]\n",
            "  ...\n",
            "  [1. 0. 0. 0.]\n",
            "  [0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0.]\n",
            "  [1. 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 1. 0.]\n",
            "  [0. 0. 1. 0.]\n",
            "  [0. 0. 1. 0.]]\n",
            "\n",
            " [[1. 0. 0. 0.]\n",
            "  [0. 0. 1. 0.]\n",
            "  [0. 0. 1. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. 1.]\n",
            "  [0. 0. 1. 0.]\n",
            "  [0. 1. 0. 0.]]\n",
            "\n",
            " [[0. 1. 0. 0.]\n",
            "  [0. 0. 0. 1.]\n",
            "  [0. 1. 0. 0.]\n",
            "  ...\n",
            "  [0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0.]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4CTnzFwsnzw"
      },
      "source": [
        "# **Core EM Code**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbAXV5YlM9p0"
      },
      "source": [
        "Write functions that will initialize our parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0uB6d0_M_b-"
      },
      "source": [
        "# Make a function to randomly generate L - P - 1 lambdas that sum to 1\n",
        "def initialize_lambda(sequence_length, motif_length):\n",
        "  # Make an empty list to represent our parameter lambda_j\n",
        "  lambda_j = []\n",
        "  # Given our sequence length and motif length, determine how many lambdas we need\n",
        "  lambdas = sequence_length - motif_length - 1\n",
        "  # Fill up our empty matrix with the right number of lambdas using random probabilities\n",
        "  for i in range(lambdas):\n",
        "    lambda_j.append(np.random.random_sample())\n",
        "  # Normalize probabilities by dividing each one by the sum\n",
        "  # Need to set sum_lambdas on the outside of the for loop so it isn't recalculated every time\n",
        "  sum_lambdas = sum(lambda_j)\n",
        "  for i, lmbda in zip(range(lambdas), lambda_j):\n",
        "    lambda_j[i] = (lmbda/sum_lambdas)\n",
        "  # Return our lambda_j parameter\n",
        "  return lambda_j\n",
        "\n",
        "# Make a function to randomly generate psi\n",
        "# Psi is a 2D matrix: 4 x P (P = motif-length) \n",
        "# Each set of 4 corresponds to ['A', 'C', 'G', 'T']\n",
        "def initialize_psi(motif_length):\n",
        "  # Make a 4 x P matrix of zeroes\n",
        "  psi = np.zeros((motif_length, 4), dtype = float)\n",
        "  # For each sub-matrix of 4, generate probabilities that sum to 1\n",
        "  for ind_i, i in zip(range(motif_length), psi):\n",
        "    psi[ind_i] = (np.random.dirichlet(np.ones(4),size=1))\n",
        "  # Return our psi parameter\n",
        "  return psi\n",
        "\n",
        "# Store all initialized parameters in a dictionary called 'params' (params = theta)\n",
        "def initialize_random_params(sequence_length, motif_length):\n",
        "    params = {'lambda_j': initialize_lambda(sequence_length, motif_length),\n",
        "              'psi0': initialize_psi(motif_length),\n",
        "              'psi1': initialize_psi(motif_length)\n",
        "              }\n",
        "    return params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC-Qv1XpvDeI"
      },
      "source": [
        "Write a function to calculate the posterior for the **E-step**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQxY3F0qvG_O"
      },
      "source": [
        "def E_step(params):\n",
        "  #log trick: \\prod_i p_i = \\exp(\\log(\\prod_i p_i)) = \\exp(\\sum_i \\log p_i) ∏ ip i=exp(log(∏ ip i))=exp(∑ ilogp i)\n",
        "  #first, compute probability of all subsequences using the background model (what does this mean?)\n",
        "  #second for the numerator for position j, you just have to subtract the jth subsequence term (using the background model) and add in the term for the jth subsequence term (using the foreground model).\n",
        "  #store posteriors as a N×(L−P) matrix\n",
        "\n",
        "  for i in (number of sequences here)\n",
        "  for j in (length of sequences) (L-P+1?)\n",
        "    initialize lambaj C[ij] = log[lambdaj]\n",
        "    compute P(Xij|Cij = 1)\n",
        "    for p in 1...6\n",
        "      C[ij] =C[ij] +log(P(Xijp)|Cij =1, psi(forground))\n",
        "  for j' ≠ j (in j' =1 ...,j-1,jth,...,L=p)\n",
        "    for p=1,...,P\n",
        "      C{ij]\n",
        "\n",
        "  return posteriors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S05xOBVOvHvh"
      },
      "source": [
        "Write a function to do the calculations for the **M-step**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGa58p1LvRHp"
      },
      "source": [
        "# We will compute the MLE\n",
        "def M_step(onehot_matrix, posteriors):\n",
        "  # Will need to edit lambda_j and psis and return updated params dictionary\n",
        "  return params\n",
        "\n",
        "'''\n",
        "Gerald's M-step\n",
        "# theta: current parameter set used to calculate posteriors\n",
        "# XXss: summary statistics of # of bases across all training sequences\n",
        "# return a dictionary containing psi, lambda\n",
        "def M_step(XXss, posteriors):\n",
        "  unnormalized_psi = (posteriors.T*XXss).T\n",
        "  unnormalized_lambda = unnormalized_psi.sum(axis=0)\n",
        "  psi = unnormalized_psi/unnormalized_psi.sum(axis=0)\n",
        "  lmbda = unnormalized_lambda/np.sum(unnormalized_lambda)\n",
        "  return({'lmbda': lmbda, 'psi': psi})\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4G4z6HyvUM1"
      },
      "source": [
        "Compute the **log likelihood**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQuPi4fJvS37"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iS8dXrNmsw2d"
      },
      "source": [
        "# **Run EM**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpOwruPhr_jA"
      },
      "source": [
        "Initialize our parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmEiILocsBGL",
        "outputId": "e25ba6b3-1c6d-4621-b510-230f392d0f1b"
      },
      "source": [
        "# Set a random seed for troubleshooting/consistency in outputs (can delete/change if desired)\n",
        "np.random.seed(2)\n",
        "\n",
        "# Set the number of sequences\n",
        "num_seqs = my_sequence_padded_num_seqs\n",
        "# Set the length of the sequences\n",
        "seq_len = my_sequence_padded_seq_len\n",
        "# Set the motif length\n",
        "motif_length = 6\n",
        "\n",
        "params = initialize_random_params(seq_len, motif_length)\n",
        "print(\"Lambda_j is:\\n\", params['lambda_j'])\n",
        "print(\"Psi0 is:\\n\", params['psi0'])\n",
        "print(\"Psi1 is:\\n\", params['psi1'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lambda_j is:\n",
            " [0.03688430721597284, 0.0021933079836355955, 0.046500359521561466, 0.036827414239112455, 0.03556228542976917, 0.027945673130994317, 0.017312870063610254, 0.0523891001032182, 0.025350193289446713, 0.02257306023566664, 0.052546694921298744, 0.04476437561616457, 0.011385197452594578, 0.04344769425308145, 0.015603248189305339, 0.06643780172029903, 0.0722446223426397, 0.041811459853969696, 0.07161742889591217, 0.006737849979282802, 0.04274282088199368, 0.005523109268094764, 0.03621830296533225, 0.008166324724378426, 0.010757482343857148, 0.05048347399917148, 0.019120168662128394, 0.009047393573026445, 0.018637469803556697, 0.0295946124711376, 0.039573896869787434]\n",
            "Psi0 is:\n",
            " [[0.08627752 0.3916258  0.25265734 0.26943934]\n",
            " [0.15720587 0.50711797 0.27876839 0.05690777]\n",
            " [0.16211317 0.44874477 0.09313926 0.2960028 ]\n",
            " [0.17508787 0.35077215 0.23367601 0.24046398]\n",
            " [0.24467594 0.12523006 0.50181065 0.12828335]\n",
            " [0.02888057 0.15382278 0.64152802 0.17576864]]\n",
            "Psi1 is:\n",
            " [[0.00503947 0.0518809  0.01270042 0.93037921]\n",
            " [0.46979067 0.21460198 0.12268652 0.19292082]\n",
            " [0.1080616  0.20211333 0.43276554 0.25705953]\n",
            " [0.00863631 0.75429829 0.10754784 0.12951755]\n",
            " [0.13184395 0.1014455  0.16500928 0.60170127]\n",
            " [0.39012558 0.13936161 0.00383005 0.46668276]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1af_j4kiOZti"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9I1WRWsu6_V3"
      },
      "source": [
        "# **Run Experiments on EM Algorithm Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XNRby2I804q"
      },
      "source": [
        "Here, we will answer the questions to Assignment 1 Part 3 regarding our updated EM algorithm model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QATNfYSQ7uJS"
      },
      "source": [
        "## 1. Plot the log likelihood as a function of EM iteration, for 100 iterations, for 30 different random initializations of the model parameter. Does the log likelihood monotonically increase every iteration of every initialization?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXPDC98w75PO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WO67ygHC76X4"
      },
      "source": [
        "## 2. Draw a sequence logo visualization of the foreground motif your model learns, $\\psi^{l}_{m, k}$. You could try LogoMaker, a Python library (https://logomaker.readthedocs.io/en/latest/). Alternatively, there are a number of web servers for doing this; you could draw samples from your foreground model, and input those drawn sequences into e.g. the WebLogo server (https://weblogo.berkeley.edu)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU_x1Agb8ySl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpV2tMRA9I2k"
      },
      "source": [
        "## 3. Now run your model using model random initializations. How do the model parameters $\\psi^{l}_{m, k}$ compare across runs? What about their log likelihoods?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPxQA-BW9RBd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ixs58dhD9WRZ"
      },
      "source": [
        "## 4. Plot a figure that shows the distribution over $C_{ij}$ for a few of the input sequences, and compare that (in the visualization) to the ground truth. How close was your model to predicting the real motif location?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEeQ51eY9cO_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHeUPqxu9nBr"
      },
      "source": [
        "## 5. Train your model using 80% of the data, holding out the remaining 20%. Evaluate the log likelihood of your held out data using the model you implemented in this assignment, and compare it to the log likelihood from the simple latent model we used in class, using the same training/held out data. Which one is better?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWZ_T8zj9qMr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17Ed0I_N9s9Z"
      },
      "source": [
        "## 6. Train your model on the atgcsequences.txt file (that had a GC-rich region embedded between two flanking AT-rich regions). Does the model work better?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq80KKxQ-Ed3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkc5IO2o-E6i"
      },
      "source": [
        "## 7. The original training set in sequence.padded.txt has 357 sequences. Randomly sample another 357 sequences of the same length (just from a simple generator, that produces each base at equal frequency) and train the model with all data. Does it still recover the same motif? What if you add 3000 noisy sequences?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EQJ9k8E-7T0"
      },
      "source": [
        "Generate 357 sequences of the same length that produces each base at equal frequency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMYZPCktUaAg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e072ffbe-8797-4929-daa2-3dff57d34cfc"
      },
      "source": [
        "import random\n",
        "\n",
        "# Number of sequences to generate\n",
        "seqs = 357\n",
        "# The minimum sequence length\n",
        "min = 40\n",
        "# The maximum sequence length\n",
        "max = 40\n",
        "# GC-content as a proportion\n",
        "gc = 0.5\n",
        "\n",
        "assert(seqs > 0)\n",
        "assert(min > 0)\n",
        "assert(max >= min)\n",
        "assert(gc >= 0 and gc <= 1)\n",
        "\n",
        "# Use probabilities for random sequence generation\n",
        "# This does not guarantee that all bases are present at equal frequency\n",
        "# But this means the sequence length does not have to be divisible by 4\n",
        "# And base pair frequencies are close to equal\n",
        "my_seqs = []\n",
        "for i in range(seqs):\n",
        "    l = random.randint(min, max)\n",
        "    seq = []\n",
        "    for j in range(l):\n",
        "        r = random.random()\n",
        "        if r < gc:\n",
        "            r = random.random()\n",
        "            if r < 0.5: seq.append('G')\n",
        "            else:       seq.append('C')\n",
        "        else:\n",
        "            r = random.random()\n",
        "            if r < 0.5: seq.append('A')\n",
        "            else:       seq.append('T')\n",
        "    my_seqs.append(''.join(seq))\n",
        "\n",
        "print(my_seqs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['GTTCCAACTAGCCGCGGGCGGTAGTGCGGTTTATTGATGT', 'ATAGCCTCTATAATACGAGCTACTTAAATTCCTAAAGTGA', 'GAAGGCCTTTGAAATGGGATGCGATGAAGGCTTCCAGACG', 'TTTGTGGAGCCAAGTGTCACGGATTAACAATAGAGACCCG', 'GCTTATGCTGGGGTAAAAAGAGTTTCTCCTGCTATAGCAG', 'TGTGGTACTATTTTATATATAAAGATCCGGCAGATATTGA', 'CACGGTCATGTATAGACCAATCTCGTCAAAGATTACTAGA', 'TAATGTTGTAAATTTCCGGTCGGAGCGCCCAAAGAGGATA', 'ACGGCCTTCGGAGTCTTTGATCTCTGAAAGTGGACCGGAT', 'CCACCCGCATGACGCCGGACCCGTGGCCAATCCGAGCCTA', 'AACTTTCTAATAATCTGTTGGAAAAACATATCTGGGTTGA', 'CCGGCTTGTTTTCGCAAGGCGCACCGATGGGACAGATCAT', 'GTATCCCTTACCTGCAAGTGTCTGACATCGGGTGAGTCCA', 'TTCAACTGTCGTCGTCCATACGGAATCGGCTAGTAGCATA', 'TTACATTACATCAACCAGCGTACGATCGTCCCCCTAGTGA', 'GTGGGTAGGGCGTCGTAAAGTACACAAACGGAGGTCGCTG', 'CAAGATCTCCGATTTCCAGCTTGGGTCGTTGATTACCAAA', 'CTTGGAACGGGATCTCAGTATGCACACGTAGACAACGGGT', 'ACGCAGGCGATTCGGCTTAAGCAACTCCGACCTACAACTG', 'CGAAAAAAGGGCCTGTGGGGAGTCAATAATACTCTTAGAT', 'TAAGCGTTTGGATGTCCCTCCCCCGAGGCTCACGGCTGCA', 'CACCGCACCCGTGAACAACGTAAATTCGTATCCTTGCGCA', 'AGATCTGTTTACGTATGCTTGGCGTAAGCTACTAGAGATT', 'GTTAAAGCAGCACTTGAATCCGCGGGCTATTATGCATGGA', 'GGCCTCAAGATCTTCGGTATCGGATGGCTACCCCTCTTCT', 'TTAGATTCGGCGTAAAATCGTGGTTCTGTTTACCCAGAAC', 'AGCGCTTGATCCAAGGCATACGTGTGTGTGTCCTTAGAGG', 'AGCGACCCTGCAAGTAGCAAACAACCGCCCGTAAGCAGTC', 'TTGGACACCGGTGTATTGCGTAGTCAACGTAGAAGATAGT', 'TACCAAATAGTTCCGAGTATAATTCCCTTGAGCCTTAAGT', 'CAACTAGGGGATAAACTGCGGCCGTCCACTACTCTGGTCT', 'CCCTACGGTGTGCCTGAACTCAGTGAAAACATAGCCCGTG', 'TGACTTGCCAAAGCTCTGCTCATTCCTTACTTGAAGACAC', 'ATTCCATTGAATCTCCTTAAGCGTACACCACCGACTCAAA', 'ATAGAACGTTCAGTTAGAGGGCCAGGTCAAGCTTTCTAAA', 'GAGGAGTACGAGAAGGCTCAAGCGGATATGGTGAGTAACC', 'GAGCCATGGCAGATATCTAGGTTAACGGCGCAAGGTCGTG', 'GTTAGCTGCGGCGACCAAATCGCATACCGAACGGATTGAG', 'CAGAACTCTCTTCAGACCTAATCTAGTGAATAGTATAATC', 'TGTGCGGAGTGTGAGGTGAGCCAAATTAGTGACCACTTAG', 'ACTACAAGTTATATTCAAATACAATTTCTCGGGGGACTAT', 'GTTTCGTTCAATTCACTCAGACCGCGCTCTAACTGGACCT', 'CACGAGAATATTCCAACCCCTGCAAGACAACAGAATATCC', 'TCTAGCAGTTTGCTCGGTTAAGAGCTCTGCTGCATTACAC', 'ATTTAAATCTAAGGGCTGGCTGGGCAGTGCGACTCACACT', 'ACGCTAGCCTTCACCGGATTATCGTCAGACCGGTCCTAAC', 'GCTTCGATTGGTAACTTTACGGTCAGGAATCCGGCACCAT', 'TCCTCGATCGGTGCGCAGCCCGACGAAGACCACTAGCGCA', 'CAATCGATCTACCGGTATAATCGCCGTGTCTACGACTAAT', 'CTCCTGAGATGATACGCTAGTAACATGATCTGCATTCTGC', 'TTGGATAATTAAGTGACCTAAGGTTCGTCGCTTTTAACAG', 'AACGAACATCGGAACAGAAATGAATTAGAGCATGGGACGC', 'TCTTTCTTGCTAACACCTGCCGATGTAGATCGATGATAGT', 'ACTTGAACAGCCTATTCCCAAGCAAACACCCTGATAGATC', 'CCGATTGGGCGGAGGAGCCACACCGATATGGCTCCGTGAC', 'TAAATGGTCGACGGCAATTTTGCCCTTCGTACTCGGCCCT', 'TCTCTCAAATCTGTATGACATCGTGTATCCGTGTTCGTCA', 'GACGAAGATATAGCCGAAGGACGTGCAGCTTAGTAAAGCC', 'TAGTCATATGTTTGCCTGCCAGGATGGTGGAGGCAAACAT', 'ACTTCGTTTAAGTGAAGGTTCAATCCCAGTCATTGTCGTA', 'GGATCTGGATAATGGTCCCGCCTCGCGCTCAACCTCAAGA', 'GAGACTGCCAACATTCTGGGGGGAATAGAGAGTGATTGTG', 'AACAGACTTCGAGATAGCGCGTTTGGTATAATCGGGCCAA', 'ATATCTACACGGTTATATTACGGAGTAAACAAATTCCTCC', 'TAATCGCGGGAATGGATATATAAGCCGTCGCGGCACGATT', 'AGTGCCATCGACAGGGCCAAACTAGGGGCCTGATTAAATA', 'CAGTGGTTGGCTTCACATGGCACTTTCCATATCTATATGA', 'GATGAGCGACCCGTGATGTCGTAGCAGATTTGCGGTGGCT', 'TGCCCCGGCGCCCCATATCGGCGATATTCTGCATTGAGAT', 'ATATTCTATGTAGACGCGACGCCGGGGGAATGATTAACCA', 'GTTATAATTAAAAAAGCTGAAATGGAGCTGCAAACTTATT', 'AAATAGTTGGTTTAACCTGTTACTACTGCGGGCAGATGGT', 'GTTGACTCTCGCGCAAGCCGGCAGGAATACTCTTAGAGCG', 'GCGATTGTTTTACTCTTCGCTGCGAGGAGCCTGGTTCAGT', 'CACAAGGCCCGTTTTCTCTCCTGAGATCATGCTAGGGTTG', 'TTGATGCATTGGGTAAGAGACCACACACCTTAACCCGCTC', 'TTACGTTACCCTCAATGGTGCGGCCTCCAAAGTACTAGTA', 'CCGGGTGTGGCGCCCAGTGCTGTGAATCTATCAGGCCGGG', 'ACAGTGATCCTCGCGTCGGCCCGGATGCTTACCGGGATGT', 'CCATGCCCCCATTGTGAGACCCGTTGCACACGTCGAAAGC', 'CAATTCGCGACTGCATAGAGACTGTGACACGTTTTGCCTG', 'CCAACGTGACGGTTAGGGAAGGTACGTGCTTGCTCCGCCG', 'ACCCAGATCTTCGTCCAATCCGATGGACCTACCGAGCGAT', 'CACTGCCATGTGTGCACGAAAGGAGATTCGGAGGTGAAGG', 'TCGAACCCCCGCCTTGTCGCATGCTGAATTATGTCGTACC', 'AACCGCTCCACCTAGGTCAAGGATCCCCGTGTGACTGATA', 'AGGGAGCAATAAATATATCCTGCGCTAGGTTATAGAGATC', 'GGTCTTACTATTGAATCGTGACTCGGAGATGGTTTTGCCG', 'GAACTGAAGATCTGAGAAACGGTCGTGAGTAAACCAGTCG', 'CAAGACCACAGACTAAACTACGCGGATGCATAACTGGAAC', 'TCGGCATTGAGAACCGGAAGATGTCAGCATGGGCATACAC', 'CTGGTGGTCGGTATTATTGCCACAGCGGTGCCCGTCGGTG', 'AAGCTATCTTTCAACTACGGAATAGTAATTTACAGATGAT', 'CGGATGATGTGGCCTCCGTGGCAACCGCGCCCTAAAGAAC', 'TTCGTGGCCATAGTAAATACGGCAGATGGTACGGCATCTC', 'CTGGCCGGGATTCCATAGGGCGTCGGGGACTATATCGGAT', 'CCAGATTGTCAAGTGCTTCCCATGATCTGCTCCTGCGCCC', 'TAATCTGGGTATCCGAACAGTCCGTTATGCCACCCTTCTG', 'GTCTCTCACAACACTAGACCCATAATTGTTGACCTATTGG', 'TCAACATACTACTTTCTTCTGACCACCGGCCGGTAGTGGC', 'CGCGCCAGCATAATTCTCGTTCATTAGGCATCAGGTCCAG', 'AGCATAGTGGGTATGTCGTGATTACCGGGAGCGAAGCTTT', 'GGGGGTCAGCCAGCTTTTAACTTCGTCACATCCGCATTAG', 'GGTCTGCTCATGCGGCTACCGGAAGTACATCAAATTAAGA', 'TTTGGAACCTATATCATGTGCCTCCGACGGGATGAGTGAG', 'TCAGGATCCTATTTGTCGCAACATGACTGCTCTTATCGCC', 'ATTCTACGGGAGACTGATCACGTTGGCGCACAGCTTGATG', 'GTATCCACCCCAGCGCAACCGTATTAAAATACTAAGATAT', 'CAGTCCATCGAGAGAGTTGTGGACATGGCCACGACGGTGG', 'GCGCCAGCGGTCACGTCGTGTGTTCGTACGTGTCCAACAC', 'GTAGCGAAGATAGTCCATGGGAACGAAACGCCTATACCTC', 'ATGTTAGGCTACAAGCTAAATCAGCGGCTGAGGTTCCAGG', 'TATTGTAATTTTATCAGATGCCCTCTAAACACAACACATC', 'GGCCTGTCTCAACGACCCGGTTGTAGCGTGATTATCTAAC', 'TTACACGCTAAGATCAATTTATGGGCAGCTAGCGAACCTG', 'TTCAAGCTGGGCACCGCATCATTACACGAGAGAAGTGCAT', 'TTTCTTGGACTCCATGTGCGACCCAGCTGGTCACTTATTG', 'GTTGGGTGATAGTAACCTATCAATTACTATAAAAGTTGGC', 'GCGGGCGGTCCCTCGGAATTGTCTATCCAGTAACCGATAC', 'CCTTGCTGTAATCCTTATTAATAAGCTGAATGTGCTCTTG', 'GCTAGCCGGCTAATCCGCGCCTGGAAACGCTAGCTTTACT', 'CGTACATCTGGACCTCTAGATGGAAAAGATGCTTCTTGTG', 'TACTACCCGTGCCGGGGCTCGATGATAACGCGGAGCCCCG', 'CTCTGAGCTTGTGGGTCGCGAGTTGGCTCGCCTCCCTTTG', 'CGAAGAGGAGTGTTCCTCGCTTTTACAGCATCTACTAAGA', 'AGTGAGCCATCCACCAATAAGCGAGGATCGTATGGAACAC', 'CAACTTCATATCGCCTGGCGTGGTTGCAATGGTCCATTCT', 'CTTCTTAAAAATTAGCGACATCCTCAGGCGCCTGGCCGTG', 'TAGCAAGCCATTGCGGCATAAAGTCCCCGCCCCTAGATCC', 'TAGGATCGCTCTCTAAAGGCTCCGTTCATGGCCGTAGCAA', 'ACTTTGGAGATCCTATGTGTCGTAGATGCGTAATAACTGG', 'CACAATCCACACTATTATATGGCGTTCTCGATACCCCGAG', 'TAATGTTACCAACAAGCCGCACTGGCTATGGTACGCGGTT', 'GTGGTTTCGTGAACCCGCCAAGCGCCTTATAATATCATGA', 'TCAGATTGTCTGAATGGGTATCAAAGAAAGTTACAGGCAG', 'TGACGAGGTCTTGCGTACTCAAAACTATTGATATCGTTGG', 'GAATCAGCACGCATAGCGAATGTACGCACGCTAACGTTGG', 'TGTCCGTGACGCACTGGCTAGGAATGGGGTGGGATCAGAT', 'TAGATTCTCACACTGAGCTACGCGCTCGAGGGGCCGTAGA', 'GCGCCCACGCCCCTTCCCCGCAATTCTACACCTCCTGCGC', 'ACCAGTTCACTTTTCGCCCAAGAAGAACGATGTATAACTC', 'TATCTGCTGTGGCGCAGGAAAAAGAGAGACTCGTCGATGT', 'CCGGAGCATCCCATCATCACCAGACGCCAGAGGCTCCCGA', 'TGCAGAAATGTTGAAAGAACCCGGCCGGTACACAGATCAA', 'CGGGTTTGAAAATAAATGAAGGCGGTTTAGCGATTTTGAT', 'TGAACTAAGTACTTTGCCTCCTGCCATTCGATGGCCCTTG', 'TCCATGCTGAACCATAACTTGATCTGGCAGATCAGCACTA', 'GAAGTGCGGGCCGCCAGCCCCCATACATGTACTGACTCCT', 'CCACGGACCAAGATAAAGAACGCTTGGCCAGGATGAGATT', 'TAACATCGCGGGCTTAAAATATTCTTTGAGGTTGCAAAGA', 'ATGCTTCATCATTAAGCTGCCAATCTGCCTCAGGAGATTG', 'TCGCGCGAGGATAACACAGACGCCCAGTCGTTAATCACCG', 'CAGCTCAGACGCATGTTCACTCGGAGAATAATCACAATCA', 'CGATTCTGATATCTCGTAAACACACTACTGATTAGACGTG', 'GAATAGCGAGTCCAACGACCCTTTATTGGAAGTGTGGGGC', 'GGGGTGGGTCATCGGATGTGTAGGTTCGTCTAGGCCCAGG', 'ATTTCCGTGGCACGCCTCGGAAAACAACTGCCGGGCCCAC', 'GGCTTGCGTGAACATGAGCCCTAAGACGTAGATCGGGCCG', 'CGAGTAGCAGGGCGAGCGACTCTTGATCGCCGCACTAAGG', 'TTTCCAATACCTGATTTGCCTTACAACCTCATCATATCGC', 'GCAGAGAGATCCACTCTAATAGATCCATCCAGTTCCATAG', 'CTGAGCAAAAGCTCAAACGACAGTAGCCACTTAATTGCCA', 'GTCAATCGAGATACATGTACGCGCATGGACCTTACTCGAT', 'CAATAAAGGTCGCTCAAGGCCTGTGTCACGCTTCATCTTT', 'GTCCCTAGGTGCTCCGCAGTCGAGTTGACACAACCCTCCT', 'TCTTCACACAAGCTAGCGCTTTACGCCCTCACAGGCGGTT', 'TTGGCGGCCCGGCTCAATATCAGGAGGGGCAACTATTGCC', 'AAGGAGATGTACGGTCGGCGTGTCTAGTACCAAACAATCA', 'ATGCAGGGTGGACTAATGAAAAGAATATGACATAAGTATG', 'TTTTCGCCATTATCGGCATACCGTGCGACGGAAACGCCGT', 'AGCAAGGTGTCACCCAAGCACGGAAAATTGCATGAAGATG', 'GAGAGATTGGAACTACGGCCGTTAAGTATGCTTCGATCTC', 'CTACTTACGAAGCTTCAAGATAATTGACTACTTCCAGGCA', 'GAGAGCAGAGGACCGAGAGATGGTTAACGGGCCCATCTCG', 'AATGACCACTGAGGGAGAGTAAGCGACACCGAACACCAGT', 'GCGGATAACACAGTCTAGATAGAGTGGTCTGCCAATAGTA', 'CCCGCGGTATAATAGTACAGTCCTCGAATGCACTATTCTT', 'AGTACTCTTAATATACCTCCTAATACCGCAGGCCTGTATT', 'GGCCCATGCGCAACGTGACGTCGAAAACTCTCATTAGGAA', 'CAACAACCTGCGACGTAAGTGAACCAGGCGGGCGCAAGGC', 'GGGTACCGCGGTATTTATCATGTCCCAGACTTATCGGGTT', 'CCCGATGTCGCAACCCCTGAGGATGCTTCAGTAAAGACGT', 'CCGAGCCGACTCCTCGGCTCATGGTTATCTCAACCAGAGA', 'TTAGTCAAGCTATAGGCGACGGAACTTGTTACCAGGAATA', 'CTTCTCAGTGTTACGATTGTTTGCCCTTCGCAGACGTTAA', 'AGAATTTAACTACTGCGTTCCCGATATAAGATGCTGAATC', 'AAGTCCTTACTGGCACGCCGAAACTCAGTTCTGCCCGCGG', 'CGGGGTGAAACCTACCGGACGTCTTAGTAATAATCTGCCG', 'GTGAAGTGTATAGACAAAAGGCGCTGGCAAATTCATACAG', 'AGAGAGGAATTGAAGTATCGTTCGGGATAACAGCCCTTAT', 'CGACCTCGAGCGGATCAGATTGGGTAGTTCCATGCACCAG', 'TCTCTTACGTACTATCTGCAATCTGTTTTGGATTAATGGT', 'GCCACGACTGCGATTGGCATATCTTGCGCTATTGAATGAC', 'ATCGTGTGGCGATGCTTATCGGGCTGCAATGTTACTGGTG', 'GTCCACTGCTTATCTGAACGATATAACGCGAGCGACGTAT', 'CACCGCCAACAGCCACTCTCTCATCTGTCTGTTTGGTGCT', 'GTTATCCGTTCGAGCCGAGCATCGGATATCGTGAAGGCAC', 'GTCAAACTCTCGGATGTCCGTGAAGGAAGTAACAGGGTGC', 'AGGACGCCAAAATTCTATAACGTCTAATACTTTTCAGGAC', 'CATGTTATGGATAATCTTAACGTCAGCGCATCGCTCGATA', 'AGTCACACCATTATGCTCTCCCTCGACTACTGCGAATAGT', 'GCATGGTGCGGTCGGCGCTGATAAGATGGAAAAGCCGGAA', 'TCTCCGTGAGGGCCTAACGTAAAGATGATGGAGGTAGATG', 'GACCTCTCGAACTTCATCCCGCGTCAGCAACCTACCGACA', 'CTCGTTGGAGGCCTAGCCGCACTTGAGCGACGGGAAATGA', 'GGCCTGGCACCAGATTCGGCCCGATATCTTTTTATCTGAC', 'ATACTTCGTAGTGGACATAAATCCCCATCTCTCAATAGGC', 'CGGTCACAGTTTCGCTTTCGATCGTAAGACCCACCTCTAA', 'CTACCTCATAGTCTCTAGCCTTTTCAGGAATATAGGTGGA', 'ACCTTCTGTTGAATTCGCCATAGAATAACTAGGTATCATC', 'GACTAGCATCACGTAAGCCTTTTTAGTGTCAATGACGCAC', 'CGATTTATTGGCAGCTGGGGACAGGCCCTTCACTCAAGCA', 'AAGACTACAAAGGCCCTCCATTAGTCTGGTGAGACTGAGG', 'CGTTTTGCTGCGATCCGGAAATGGGGCATTGTTTTTGGGA', 'GCTGGAAGATGGGTGATGCCCTTTTGTTCTGCCAATGCGT', 'GGGGCTTTGTATCAGCTGCCACTTGAGAGGCAACCTTCGT', 'CTCTCTTTGTGCTGAATTTTGTCTCTGCTCACAGGCTATA', 'CGCATGAGTTGCCGTTCAGTTACAAGTAATCCAACGCTGT', 'CAAGCGAACTATTTCTGCATATATTCTCTTGGAATGGAAG', 'TACTACGCTTCCACCACCAACAATTACAGGCTTATGCCTA', 'GGGGATTGAATTTTTAGGATATACAACGAAAAAGATACCG', 'AAAATCAGTTGTACAGCATAACGCTGTCATCGCACACGTA', 'TGCACAGCCCCAGCGGTGAGGCGGGGAGTCCTATACTTGG', 'CAAATTCTCGAGGGACTCAGGTGTGTCAGCGCGGTCTCAT', 'TTTGATGACATTATATGAGTTTCGGGCGCAAAGAGTAGAT', 'TAATTGAGCTACGAGGCGTAAGTTATGTCGTAAAAGGTAC', 'GGGACGTAGGAGAGACTGACTTACCCCTGAGAACGGGAGA', 'TTGGGGCCGGATTGCAAAGTAAGAATAAATGCCCCGACTC', 'CTTACTCCGGACAAGTAACTGAAGGCCGGCCTGCGCTTTT', 'GGAGGAGTAGGGATCGCGGCCTCGTATTAATCAACCTGCG', 'AGCGGCGACCCCTTGAAGCAAATCTTCCTCTGCGTGGTCC', 'GTCCGAAACTAAGAAATGGTAAGCTAGTGCCGCAAGTTGA', 'TGCGACGGACAACGTCGCTCCCCTGTAGAAGGGTGAATAG', 'CCCAGGACAGAGTCCATTCCAGATGTCACGGAGCGTCTAT', 'TAGGACAAGGCGAACAAAGGGCCGACGCAATGGGTCCGTA', 'GGTTATCAGTGGACGGGGTGCAAATTGTGGTCTGGCACAA', 'CGCCGGCAAATGAGGCACTAAAAGTCGAGCATGCTGCGGT', 'CCTTCTCCCCCAAACCTATTGTTAGGTTGGAGGGCAGTTC', 'AAAGTTGCCTCATTTAAGTGATGGATAACTCAGGTGAAAT', 'GCGGTGTAGTAAGTAACTGCTCAAATGTAGGCAACCTTTA', 'ATACTACTGCGGGCTCGCTCACCTCTCGACTCCGGACGAG', 'TGGCCCTGAGGCACTCTTGTCGACGTAGCTCGCAAGTATC', 'TCCTACTGCTGGGCCACGCATTTAGGATCATTGGGTAATA', 'CTTACGTAACCCTTAGCATGTCCATGGTGGATCGCGCGGT', 'GCCTCGGCCTTATACGCATGCGCGTACCCTGCATGTATAG', 'AAGCACAATGAGGAGTCTCCCTTACTCGCCCCCCAGCGCA', 'TCTGTCCTTCTTAATTAAGGGCAAGCTATGGTCGCAAGCG', 'TTGCAACGGAGTACTGACCTAGGGATAGATCTGGTCGTAC', 'TCGAAGTTGGGACCGATGCATTTGGAGTCACTCGTAACTC', 'TCATCTCGTTAATAAGACAGCCGCTGACACAAAAGCAGGT', 'AGGGTAGTAAAATGTCTCGCGAAAAGCTAGGAGGATGATC', 'CGCTCCCATTCACCAGGGGACCGTACTCGTTTCTATCGTA', 'GGGGCGATTTTTGGAGTGCCGTAAGAAACGTGCGGCTCTA', 'TCAGTACGACGTTCGTACAGGCCTGTGCACCCCGATACAC', 'CAGTGTTTATTAATGAAGATTTGTCGTGCACAAGAGACAT', 'ACATCAAGCGATCTTGTCAGCCGCCAAATATCACGCCTGC', 'CATGGCACCACGTAACAGCTCAACTCATTCGAGGGTGAAA', 'TGCGGCCGTGCTTAAGGGCCAATCTTGTCGTGTTTTATAG', 'AGAGTATCTCGTCCGGAACACGCATTACCTCGTGGGGCTA', 'TTCTTTCGCGGAGCTGATCGCCATACTTCGACGATATTGC', 'CGACGCAAGGTAGAGCTAGAGATCTCGCGTCGATACTGTT', 'ATGCGCCTATTTATGGTCTCCAACCATTTTGAAGAGCTGC', 'TATAGGTACGCTGCGCATTCCGTTCGTGGTCGGGCAGGCC', 'ATGCGATCTGATTTATAATTGTAATTAAACGCAATTGCCT', 'ACTCTTATCCTAACTGAAGGAACACCAACTGGCGGCCCCC', 'TTGGGATAAGGGTCACCAACCCCTGACCTCTCCCCTTCGA', 'GATGTTTCTCGTAGACTGGCCCGACCAAACTAATGCTACT', 'TTTACGTCCGTACTTTCCTTTTAGGAATTACTACCACGGG', 'ACCAATGGACACCTGACATTCGACATAAACCCCCGAGGGC', 'TGCGCGACATGGTGGGGAAGATGTGAATCACGGAGATCAG', 'TCCTGATTTCTTGAACTACGAAAACCCAAAACAAGGACCC', 'GGCAGGACAACCGGTCGCTCTTAGGCGAAGGTACTGACCA', 'CTTTCCTCTAATCCAATTCAGGTTGCGATACTCCAGCGTG', 'ACCACTCTATTATAAGGTATCGTATGTTTAGACACGCGGC', 'GCGCTACGCCAATCGCTGAGGCTCAATCCGAACGCAACGA', 'TGCGAGGAAGAAAACGGTGGGTCGGCCTCTGTTGCTCCCG', 'CAGCTTGCAGGGGCGCAGACCTAGGGATGGAAAACGTCTT', 'TGTTCCGTGAAGGCAGGCAAAAGTAGGGAGTAATTTTCTG', 'GCTCGGTATGTTCTTAAGCGATGACAGGTAATACGCTGAG', 'CCCCAGCAAGGCTACCGCGTACCCTGGCCCATGTGCCCAA', 'TCTATGTCCGGTGGTTAAATCGGAACTCGTCTGGCCCCCG', 'TCCCGCCCGAGGAATGCGTATGGCAACTCGCGTCTGCTAC', 'TGAACTTCTATGGCGGTTAGCGCACTTGCCTACGTTCCGC', 'TATTTTATGGGCTATCAGTTAGAACCCGGTTAGGGCCCGG', 'AGTGTCGCCATCAATACTAGCCAGCCCCGGACCGACTGCC', 'TTTATGTGGACACTGGCACCCCATCTGTCCGGGACCTACC', 'GTGACCTGAAGGTGCTCGCCCCTTACAGATTCTTACTTGT', 'CGCCTCCTCTCGTGCGTGGTTGCCATGAATGACGCAGTCG', 'TGGGACAGGGTATTCCTTTTTGCGTCGTTCGGGTCGTTTC', 'TGTTGAGCGTTCCGAGTATTCTACGTGCGGAAGACAGATA', 'ACGGCGCTGGTAAAGCTAAGCTGAGTCCTGGACAAAGTGA', 'GCCCGATATCCAGCCCGCTCTTATATATGTCATCTTGGAT', 'ATCGCACCGCCGCGAGTCCAACGACAGAGGCACATGGCCC', 'GATATGAATGGCTATCATAGTTGGACCTTATTCAAGAATT', 'GCTTTCGCAATCTTATCACGCCCGGCGGTTCTAGTTAGAA', 'GACTGTGGTCACTCAGCCACGCAACAACCTTTTTTATGGC', 'AGCGGCTCACTTGTAAGGGGTGTACTATTCTCCTCGAGAC', 'CTTAGACAGGATCGTCGACCTTGCAGCTTCGTAAGCGGCA', 'AGCTATGATACGTAATTAAGCTCTACTACCTGGCGCTTTT', 'CGACAACGCAGGCGGCTGGGAACCTAGTCGGTTATGGTGT', 'CAGTAGCGGTTGACCCTTGTAATTCCGAGAATGAAAAACC', 'CTATCTCATTAGCCCAGTCTTGAAACAGCTGAACATGACG', 'CGTATATGTTAGACAAGTATACGGGGTAATGATTCGGCCC', 'GAGCCCCTATAAACGATTTTTTTCTGAAAAATGCGCGTTT', 'GCGCAGGGGCCCTGGGGACTTTAGTTAACCAAGCGAGTAA', 'CCGACGCCCACCCCTCTAGGACGCCTCACTCGCCCCAGAG', 'GCACAAAGTAGATCGATTTCTCATTTCCACCGCTTGTGCT', 'CAAGTTGCTCAGACAGCCTCAGACGCAATCGTGCCGTTTG', 'CACTCATACGCAGAAGAGGCACCGTGGGTACGCTTGGTTA', 'TGTTCTAGCGGGAAGCATAGCTCCCAATATCGGGGGCGGT', 'CAACTGGTCGCCTACGAGGATGACTCTAAAATTCCTGGTC', 'CCACTACACTGTACTCGCAAGCCTTTTTCTGAGCTGAGAA', 'ACTTCGGGAAAAATGCTGAGTGAGGACCTACAAGGGGCCC', 'TGGCTTACAGCCGAAAATGGTTCGCAAAAAAGTTGGCAGG', 'ACTTCTGGTACAAAGAAGTCAATGGACCAGTCCGGAGCAT', 'GAGCAGAGTCGCTATCCATTGCCAACATTAATATTTGCCA', 'AATCTGTAATCTCATTTAGGCCGAGAGTAGGCTCGGGCAT', 'TCGCACCCTGTTCTTGGGTGTGGCCGCGATGTTACTCCAG', 'TAGTCCATACCCGACAATGATCTCGAATAAAGTCTGCAGG', 'TTAATCCTACTAGCCGCATTCTTATCCATAAAAAGTGGCG', 'CAGTGGGATCAACAACGTCCTCTAGATCATCACCTATGTA', 'CAGTAGTTAAGAGCGGCGCTTGGCCTAACGGATGGTCGAT', 'GACTCCCCACAGACATGGGCACATTGAACGGACGGCGCCC', 'AGCTTATAGGCGTGTCATACCCAGTGGCAACTCTGGATCT', 'AGGGAATACAAGGAATGGGGCACCAATTCATAGACTTGCG', 'TCTGCAGGATAGAGTGATCGCCAATGCATAGAGATCCCCT', 'TGTGGGTCCGTGTATGGTTTACTTATATCGGGCCAGGTTC', 'GCCAATAGTGTCTGTAGGACCATGTTAACGCCTGTTTACA', 'GTAAAATCCGGGAATCGCATGGGGACTGACCGCGAGTAAG', 'CAATAAGCAGATGAGTGTTCACATAAAATGTCCTCTGTCA', 'GTACCCAAATCTATCAATGACGAGTTAGTCTGCGGATCTA', 'ATTGTCTATCCCGAATACAGTGACTCCGTATCGATATATA', 'AATAGAAACGTCCCGAGGGTGGTTGCTTGTGATTCCCTCC', 'CTTACTAAAGCGCGACCATTTTCCGCCGAACTCTGGCACT', 'AGAGTAGGTTCAAGAAGGTTTCCGGACCTTAAATAAGTAC', 'TTCGCGACAGGACTTACGATGCTGGCTGTTTATTCACCCT', 'TTATTAAACACCTCTGCTTATGACCACTTGCACCACATAC', 'CGCTAAAGTTGCCATGAACTGAACAACCTCCAGTGCCGCT', 'CCAGCGCGTTCCTCAACGCTCCTGAGAGTTGCCCGATCTA', 'GCCCGCAGGTGTTGCATGTCCGGCTGAACACGTCAGAAGG', 'GCGGAAACATGCCCGCTGCTCACTGATATTGTAGGCCTTC', 'ATTGAGTGTAAGTGCAGATCGTTCTACTAATAAACATCTC', 'GGCCCACCACAGGTTGGAGTCCCAGAGCCGTTCTCCTCAC', 'GATCCCCGGGGTCAACTTTGGTCTGAACGCTCCATCTGAG', 'AGTTTTTGGCGGTGTCTAAAGATCGATCAAGTGATACTTA', 'TTCTACGGTTCATCCCGTATCCGTAGCTCACTCTCCGGGC', 'GACCACAGCCTTGCCGTCATCCGTGGCAACTTGCTCCCTG', 'ATCCCAAATCGCTAATTCCATGCGAGCCTGCAGAAGGCAC', 'GGACATTTTAGAAGGTCTCTCAGCCGATCATAACCAGTAT', 'GTACTCTCAACAAGGCCGGATAAACATAAAAGGTACATCT', 'ATAATTCCTACACCAAAGAGCGACAGACCTCCACCGACAG', 'GCTGCACCAAATTTTTAATGCTCGGGCAGCCGTTGCAATC', 'CTGCACAAGGGGGCGCGCAGCAGCCGGCAGTGTTTACTAC', 'CCAAAAACCAACGCGTGCAGGCTTGCTAGTCTTAGATAGC', 'GTGATCGGGTCTGTCACGTATAGGTTTACGGTAGAATGAG', 'CCGAGAAAAACGTCGAACCGGAAAGACAAATAGGACTCTC', 'CTGGCGCGTGGCATATGGCCCGGGGTCTGGCGAAAGTTCT']\n"
          ]
        }
      ]
    }
  ]
}